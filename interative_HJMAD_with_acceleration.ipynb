{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ipywidgets import FloatSlider, Button, Output, VBox, HTML, HBox, Dropdown, interact, Output, Checkbox, FloatText\n",
    "from IPython.display import Image, display, clear_output, Math\n",
    "\n",
    "from test_functions1D import MultiMinimaFunc_numpy, Sinc_numpy, Sin_numpy, DiscontinuousFunc_numpy, MultiMinimaAbsFunc_numpy\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# HJ Moreau Adaptive Descent\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class HJ_MAD:\n",
    "    ''' \n",
    "        Hamilton-Jacobi Moreau Adaptive Descent (HJ_MAD) for nonconvex minimization.\n",
    "        Inputs and Outputs descriptions remain unchanged.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, f, x_true, x0, delta=0.1, int_samples=100, t_vec = [1.0, 1e-3, 1e1], max_iters=5e4, \n",
    "                 tol=5e-2, theta=0.9, beta=[0.9], eta_vec = [0.9, 1.1], alpha=1.0, fixed_time=False, \n",
    "                 verbose=True, accelerated=False,momentum=0.5, plot_parameters = [-30,30,None],\n",
    "                 sample_bool=False):\n",
    "      \n",
    "        self.delta            = delta\n",
    "        self.f                = f\n",
    "        self.int_samples      = int_samples\n",
    "        self.max_iters        = max_iters\n",
    "        self.tol              = tol\n",
    "        self.t_vec            = t_vec\n",
    "        self.theta            = theta\n",
    "        self.x_true           = x_true\n",
    "        self.x0 = x0\n",
    "        self.beta             = beta \n",
    "        self.alpha            = alpha \n",
    "        self.eta_vec          = eta_vec\n",
    "        self.fixed_time       = fixed_time\n",
    "        self.verbose          = verbose\n",
    "        self.accelerated      = accelerated\n",
    "        self.momentum         = momentum\n",
    "        # Plotting Parameters\n",
    "        self.plot_parameters  = plot_parameters\n",
    "        self.sample_bool      = sample_bool\n",
    "\n",
    "      \n",
    "        # check that alpha is in right interval\n",
    "        assert(alpha >= 1-np.sqrt(eta_vec[0]))\n",
    "        assert(alpha <= 1+np.sqrt(eta_vec[1]))\n",
    "    \n",
    "    def compute_grad_uk(self, x, t, eps=1e-14):\n",
    "        ''' \n",
    "            Compute the gradient of the Moreau envelope\n",
    "        '''\n",
    "        f = self.f\n",
    "        delta = self.delta\n",
    "        # Compute the function of the random variable y sampled from N(x,delta*t)\n",
    "        standard_dev = np.sqrt(delta * t)\n",
    "        y = standard_dev * np.random.randn(self.int_samples) + x  \n",
    "        exp_term = np.exp(-f(y) / delta)\n",
    "\n",
    "        # Compute Denominator and average over the samples (add eps for 0 error)\n",
    "        v_delta = np.mean(exp_term) + eps\n",
    "\n",
    "         # Compute Numerator and average over the samples\n",
    "        numerator = np.mean(y * exp_term)\n",
    "\n",
    "        # Compute Gradient at uk\n",
    "        grad_uk = (x - numerator / (v_delta))\n",
    "\n",
    "        # Compute estimated uk\n",
    "        uk = -delta * np.log(v_delta)\n",
    "\n",
    "        # Compute Estimated prox_xk\n",
    "        prox_xk = numerator / v_delta\n",
    "\n",
    "        # Compute the standard error for uk\n",
    "        sample_var = np.var(-delta *np.log(exp_term+ eps), ddof=1)  # Sample Variance\n",
    "        se_uk = np.sqrt(sample_var) / np.sqrt(self.int_samples) # Standard Error\n",
    "\n",
    "        # Return Gradient at uk, uk, prox at xk and standard error in uk sample\n",
    "        return prox_xk, grad_uk, uk, se_uk, y\n",
    "\n",
    "\n",
    "    def update_time(self, tk, rel_grad_uk_norm):\n",
    "        '''\n",
    "            time step rule\n",
    "\n",
    "            if ‖gk_plus‖≤ theta (‖gk‖+ eps):\n",
    "            min (eta_plus t,T)\n",
    "            else\n",
    "            max (eta_minus t,t_min) otherwise\n",
    "\n",
    "            OR:\n",
    "            \n",
    "            if rel grad norm too small, increase tk (with maximum T).\n",
    "            else if rel grad norm is too \"big\", decrease tk with minimum (t_min)\n",
    "        '''\n",
    "\n",
    "        eta_minus = self.eta_vec[0]\n",
    "        eta_plus = self.eta_vec[1]\n",
    "        T = self.t_vec[2]\n",
    "        t_min = self.t_vec[1]\n",
    "\n",
    "        if rel_grad_uk_norm <= self.theta:\n",
    "            # increase t when relative gradient norm is smaller than theta\n",
    "            tk = min(eta_plus*tk , T)\n",
    "        else:\n",
    "            # decrease otherwise t when relative gradient norm is smaller than theta\n",
    "            tk = max(eta_minus*tk, t_min)\n",
    "\n",
    "        return tk\n",
    "    \n",
    "    def gradient_descent(self, xk, tk):\n",
    "        # Compute prox and gradient\n",
    "        prox_xk, grad_uk, _, _, samples = self.compute_grad_uk(xk, tk)\n",
    "\n",
    "        # Perform gradient descent update\n",
    "        xk_plus1 = xk - self.alpha * (xk-prox_xk)\n",
    "\n",
    "        return xk_plus1, grad_uk\n",
    "\n",
    "    def run(self, animate,plot_bool=True):\n",
    "        xk_hist = np.zeros(self.max_iters)\n",
    "        xk_error_hist = np.zeros(self.max_iters)\n",
    "        rel_grad_uk_norm_hist = np.zeros(self.max_iters)\n",
    "        fk_hist = np.zeros(self.max_iters)\n",
    "        tk_hist = np.zeros(self.max_iters)\n",
    "\n",
    "        xk = self.x0\n",
    "        x_opt = xk\n",
    "        tk = self.t_vec[0]\n",
    "        t_max = self.t_vec[2]\n",
    "\n",
    "        _, grad_uk, _, _, _  = self.compute_grad_uk(xk, tk)\n",
    "        rel_grad_uk_norm = 1.0\n",
    "\n",
    "        if self.accelerated:\n",
    "            xk_minus_1 = xk\n",
    "\n",
    "\n",
    "        fmt = '[{:3d}]: fk = {:6.2e} | xk_err = {:6.2e} '\n",
    "        fmt += ' | |grad_uk| = {:6.2e} | tk = {:6.2e}'\n",
    "\n",
    "        for k in range(self.max_iters):\n",
    "            \n",
    "            # Update History\n",
    "            xk_hist[k] = xk\n",
    "            rel_grad_uk_norm_hist[k] = rel_grad_uk_norm\n",
    "            xk_error_hist[k] = np.linalg.norm(xk - self.x_true)\n",
    "            tk_hist[k] = tk\n",
    "            fk_hist[k] = self.f(xk)\n",
    "\n",
    "\n",
    "            if animate:\n",
    "                self.plot(k, xk, tk,xk_error_hist[k])\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(fmt.format(k + 1, fk_hist[k], xk_error_hist[k], rel_grad_uk_norm_hist[k], tk))\n",
    "\n",
    "            if xk_error_hist[k] < self.tol:\n",
    "                tk_hist = tk_hist[:k + 1]\n",
    "                xk_hist = xk_hist[:k + 1]\n",
    "                xk_error_hist = xk_error_hist[:k + 1]\n",
    "                rel_grad_uk_norm_hist = rel_grad_uk_norm_hist[:k + 1]\n",
    "                fk_hist = fk_hist[:k + 1]\n",
    "\n",
    "                print('-------------------------- HJ-MAD RESULTS ---------------------------')\n",
    "                print('HJ-MAD converged with rel grad norm {:6.2e}'.format(rel_grad_uk_norm_hist[k]))\n",
    "                print('iter = ', k, ', number of function evaluations = ', len(xk_error_hist) * self.int_samples)\n",
    "                \n",
    "                break\n",
    "            elif k == self.max_iters - 1:\n",
    "                print('-------------------------- HJ-MAD RESULTS ---------------------------')\n",
    "                print('HJ-MAD failed to converge with rel grad norm {:6.2e}'.format(rel_grad_uk_norm_hist[k]))\n",
    "                print('iter = ', k, ', number of function evaluations = ', len(xk_error_hist) * self.int_samples)\n",
    "                print('Used fixed time = ', self.fixed_time)\n",
    "\n",
    "            if k > 0:\n",
    "                if fk_hist[k] < fk_hist[k - 1]:\n",
    "                    x_opt = xk\n",
    "\n",
    "            grad_uk_norm_old = np.linalg.norm(grad_uk)\n",
    "\n",
    "            # Accelerate\n",
    "            if self.accelerated and k > 0:\n",
    "                yk = xk + self.momentum * (xk - xk_minus_1)\n",
    "                xk_minus_1 = xk\n",
    "            else:\n",
    "                yk=xk\n",
    "            # Perform GD\n",
    "            xk, grad_uk = self.gradient_descent(yk,tk)\n",
    "    \n",
    "            # Compute Relative Grad Uk\n",
    "            grad_uk_norm = np.linalg.norm(grad_uk)\n",
    "            rel_grad_uk_norm = grad_uk_norm / (grad_uk_norm_old + 1e-12)\n",
    "\n",
    "            if not self.fixed_time:\n",
    "                tk = self.update_time(tk, rel_grad_uk_norm)\n",
    "\n",
    "\n",
    "        if plot_bool:\n",
    "            self.plot(k,xk, tk,xk_error_hist[k],plot_bool)\n",
    "\n",
    "        algorithm_hist = (xk_hist, tk_hist, xk_error_hist, rel_grad_uk_norm_hist, fk_hist)\n",
    "                     \n",
    "        return x_opt, algorithm_hist\n",
    "    \n",
    "\n",
    "    def plot(self, k, xk, tk,error,plot_bool=True):\n",
    "        intervalx_a, intervalx_b,plot_output = self.plot_parameters\n",
    "\n",
    "        # Use the selected global function to compute f_values\n",
    "        x_range = np.linspace(intervalx_a, intervalx_b, 500)  # Adjust based on selected function\n",
    "        f_values = np.array([self.f(x) for x in x_range])\n",
    "\n",
    "        # Calculate Moreau envelope at xk\n",
    "        prox_xk, _, uk, se_uk, samples  = self.compute_grad_uk(xk, tk)\n",
    "        #xk_plus1 = xk - self.alpha * grad_uk\n",
    "        #estimated_moreau_value = self.f(prox_xk) + (1 / (2 * tk)) * ((prox_xk - xk) ** 2)\n",
    "\n",
    "\n",
    "\n",
    "        # Compute the Error\n",
    "        #xk_plus1 = xk - self.alpha * grad_uk\n",
    "        if k==0:\n",
    "            error = np.linalg.norm(self.x0 - self.x_true) \n",
    "\n",
    "        # The function that prox minimizes\n",
    "        prox_func_values = np.array([self.f(x) + (1 / (2 * tk)) * (x - xk) ** 2 for x in x_range])\n",
    "\n",
    "        # Plot f(x) \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x_range, f_values, label='f(x)', color='black')\n",
    "\n",
    "        # Plot the function that prox minimizes at xk and its estimated minima\n",
    "        plt.plot(x_range, prox_func_values, label=r'$f(x) + \\frac{1}{2T} (x - x_k)^2$', color='orange')\n",
    "        plt.scatter(prox_xk, self.f(prox_xk) + (1 / (2 * tk)) * (prox_xk - xk) ** 2,\n",
    "                    facecolors='none',edgecolors='orange', label=r'Estimated Prox at $ x_k$, $prox_{tf}(x_k)\\approx x_k-t_k\\nabla u^{\\delta}(x_k)$ and' +\n",
    "                    f'\\nthe Estimated Global Minima of ' + r'$f(x) + \\frac{1}{2t_k} (x - x_k)^2$',\n",
    "                    s=100, zorder=4, marker='s')\n",
    "        \n",
    "        # Samples\n",
    "        if self.sample_bool:\n",
    "            samples_func_values = np.array([self.f(sample) + (1 / (2 * tk)) * (sample - xk) ** 2 for sample in samples])\n",
    "            plt.scatter(samples, samples_func_values,color='blue', label=r'Samples', zorder=4, marker='*')\n",
    "        \n",
    "\n",
    "        # Plot Moreau Envelope Estimation with error bars\n",
    "        plt.errorbar(xk, uk, yerr=se_uk, label=rf'Estimate Moreau Envelope Value, $u(x_k,t_k))$, where $t_k={tk:.1f}$',\n",
    "                 color='red', fmt='o', markersize=5, zorder=4, marker='x', capsize=5)\n",
    "\n",
    "        # Plot Points for Current, Next, Initial Iteration, and Global Minima\n",
    "        plt.scatter(xk, self.f(xk), label=r'Current Iteration, $f(x_k)$', zorder=6,s=150,  marker='^')\n",
    "        plt.scatter(self.x0, self.f(self.x0), color='green', label=r'Initial Iteration, $f(x_0)$',s=100, zorder=4, facecolors='none',edgecolors='blue')\n",
    "        plt.scatter(self.x_true, self.f(self.x_true), color='black', label=r'Global Minima, $f(x_{true})$',s=100, zorder=5, marker='x')\n",
    "        #plt.scatter(xk_plus1, self.f(xk_plus1), color='cyan', zorder=4, label=r'Next Iteration, $f(x_{k+1})$', marker='^')\n",
    "\n",
    "        plt.title(f'f(x) and Moreau Envelope\\nIteration {k}, Error={error:.3e}, Tol={self.tol:.3e}')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Function Value')\n",
    "\n",
    "        # Set limits and grid\n",
    "        plt.xlim(intervalx_a, intervalx_b)\n",
    "\n",
    "        # Dynamically set the y-limits based on function outputs\n",
    "        y_min = np.min(f_values)\n",
    "        y_max = np.max(f_values)\n",
    "\n",
    "        if y_max < 0:\n",
    "            # If all values are negative, set the limits to give some visual space\n",
    "            plt.ylim(1.2 * y_min, 0)  # Set lower limit 20% below min, upper limit at 0\n",
    "        elif y_min > 0:\n",
    "            plt.ylim(0.8 * y_min, 1.2 * y_max)  # 20% less than the min if min is positive\n",
    "        else:\n",
    "            plt.ylim(1.2 * y_min, 1.2 * y_max)  # 20% more than the min if min is zero or negative\n",
    "\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.95), ncol=1)\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "        plt.minorticks_on()\n",
    "        plt.gca().xaxis.set_minor_locator(plt.MultipleLocator(1))\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "\n",
    "        # Save the figure as a PNG file\n",
    "        plt.savefig(\"MAD_interactive_plot.png\", format='png', bbox_inches='tight')\n",
    "        plt.close()  # Close the plot to free up memory\n",
    "\n",
    "        if plot_bool:\n",
    "            with plot_output:\n",
    "                clear_output(wait=True)  # Clear previous plot\n",
    "                display(Image(filename=\"MAD_interactive_plot.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# UI Class to Interact with HJ_MAD\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class HJ_MAD_UI:\n",
    "    def __init__(self):\n",
    "        self.init_hj_mad()\n",
    "        self.create_ui()\n",
    "\n",
    "    def init_hj_mad(self):\n",
    "        # Output widget to display the plot\n",
    "        self.plot_output = Output()\n",
    "        self.plot_results_output = Output()\n",
    "\n",
    "        # Fixed Variables\n",
    "        tol = 5e-4\n",
    "        eta_min = 0.9\n",
    "        eta_plus = 5.0\n",
    "        eta_vec = [eta_min, eta_plus]\n",
    "        theta = 1.0\n",
    "        beta = 0.0\n",
    "        self.t_min = 0.1\n",
    "\n",
    "        # Set Initial Interactive Values\n",
    "        int_samples = int(200)\n",
    "        delta = 0.1\n",
    "        t_init = 220\n",
    "        t_max = 230\n",
    "        max_iters = int(50)\n",
    "        alpha = 0.1\n",
    "\n",
    "        # Default Function Settings\n",
    "        intervalx_a, intervalx_b = -30, 30\n",
    "        plot_parameters = [intervalx_a, intervalx_b,self.plot_output]\n",
    "        f = MultiMinimaFunc_numpy\n",
    "        x_true = -1.51034568\n",
    "        self.gamma = 1.89777\n",
    "        x0 = -30\n",
    "\n",
    "        # Create HJ_MAD instance with initial parameters\n",
    "        self.hj_mad = HJ_MAD(f=f, x_true=x_true, x0=x0, delta=delta, int_samples=int_samples, \n",
    "                             t_vec=[t_init, self.t_min, t_max], max_iters=max_iters, tol=tol, \n",
    "                             theta=theta, beta=beta, eta_vec=eta_vec, alpha=alpha, \n",
    "                             fixed_time=False, verbose=False, accelerated=False,\n",
    "                             plot_parameters=plot_parameters)\n",
    "\n",
    "    def update_hj_mad_delta(self,b):\n",
    "        self.hj_mad.delta = self.delta_slider.value\n",
    "        self.plot_hj_mad()\n",
    "        self.update_standard_error_display()\n",
    "\n",
    "    def update_hj_mad_int_samples(self,b):\n",
    "        self.hj_mad.int_samples = int(self.int_samples_slider.value)\n",
    "        self.plot_hj_mad()\n",
    "        self.update_standard_error_display()\n",
    "\n",
    "    def update_hj_mad_t_init(self,b):\n",
    "        self.hj_mad.t_vec[0] = self.t_init_slider.value\n",
    "\n",
    "        # Don't let t_max become smaller than t_init\n",
    "        if self.t_max_slider.value < self.t_init_slider.value:\n",
    "            self.t_max_slider.value = self.t_init_slider.value\n",
    "        self.plot_hj_mad()\n",
    "        self.update_standard_error_display()\n",
    "\n",
    "    def update_hj_mad_t_max(self,b):\n",
    "        self.hj_mad.t_vec[2] = self.t_max_slider.value\n",
    "\n",
    "        # Don't let t_max become smaller than t_init\n",
    "        if self.t_max_slider.value < self.t_init_slider.value:\n",
    "            self.t_init_slider.value = self.t_max_slider.value\n",
    "        self.update_standard_error_display()\n",
    "\n",
    "    def update_hj_mad_max_iters(self,b):\n",
    "        self.hj_mad.max_iters = int(self.max_iters_slider.value)\n",
    "\n",
    "    def update_hj_mad_alpha(self,b):\n",
    "        self.hj_mad.alpha = self.alpha_slider.value\n",
    "\n",
    "    def update_hj_mad_momentum(self,b):\n",
    "        self.hj_mad.momentum = self.momentum_slider.value\n",
    "\n",
    "    def update_t_threshold_display(self):\n",
    "        \"\"\"Update the display for the t_threshold and compute its value.\"\"\"\n",
    "\n",
    "        # Create the HTML string\n",
    "        html_content = \"\"\"\n",
    "        <div style=\"border: 1px solid black; padding: 10px; border-radius: 5px; margin-top: 10px;\">\n",
    "        <h4 style=\"margin: 0;\">Time Threshold <i>(Theoretical Lower Bound on Intial Time Steps for Convergence)</i></h4>\n",
    "        <div style=\"font-family: Times New Roman, serif; font-size: 14px;\">\n",
    "            <p><strong>t<sub>threshold</sub> = {}\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate t_threshold\n",
    "        if self.gamma is not None:\n",
    "            self.t_threshold = (np.linalg.norm(self.hj_mad.x_true - self.x_0_slider.value)**2) / (2 * self.gamma)\n",
    "            # Use str.format to insert the calculated value into html_content\n",
    "            html_content = html_content.format(f\"{self.t_threshold:.2f}, where</strong>:</p>\")\n",
    "        else:\n",
    "            # If self.gamma is None, modify html_content to show 'UnDefined'\n",
    "            self.t_threshold_display.value = html_content.format('UnDefined</p>')\n",
    "            return\n",
    "\n",
    "        # Make sure t_min is less that t_threshold (this isn't a necessary \n",
    "        # condition as long as t_min<=t_init but this gives the user more choice)\n",
    "        if self.t_threshold < self.t_min:\n",
    "            self.t_min = self.t_threshold*0.8\n",
    "            self.t_max_slider.min = self.t_min\n",
    "            self.t_max_slider.min = self.t_min\n",
    "\n",
    "        if self.t_threshold > self.t_max_slider.max:\n",
    "            self.t_max_slider.max = self.t_threshold*1.5\n",
    "            self.t_init_slider.max = self.t_threshold*1.5\n",
    "        else:\n",
    "            self.t_max_slider.max = 100\n",
    "            self.t_init_slider.max = 100 \n",
    "\n",
    "        if self.hj_mad.fixed_time:\n",
    "            html_content += f\"\"\"<p style=\"margin-left: 20px;\">\n",
    "                • t<sub>0</sub> ≥ ||x* - x<sub>0</sub>||<sup>2</sup> / (2γ) = t<sub>threshold</sub>\n",
    "            </p>\n",
    "            </div>\n",
    "            </div>\"\"\"\n",
    "            # Update the display\n",
    "            self.t_threshold_display.value = html_content\n",
    "            return\n",
    "        \n",
    "        html_content += f\"\"\" <p style=\"margin-left: 20px;\">\n",
    "                • T ≥ t<sub>0</sub> ≥ ||x* - x<sub>0</sub>||<sup>2</sup> / (2γ) = t<sub>threshold</sub>\n",
    "            </p>\n",
    "            <p style=\"margin-left: 20px;\">\n",
    "                • Also T ≥ t<sub>0</sub> ≥ τ > 0, τ = {self.t_min:.2f}\n",
    "            </p>\n",
    "            <p style=\"margin-left: 20px;\">• T, max time. τ, min time. t<sub>0</sub>, initial time. </p>\n",
    "        </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        # Update the display\n",
    "        self.t_threshold_display.value = html_content\n",
    "\n",
    "    def update_standard_error_display(self):\n",
    "        \"\"\"\n",
    "        Standard Error is a measure of how much the sample mean will vary from \n",
    "        sample to sample.\n",
    "        \"\"\"\n",
    "        # Compute the standard Deviation and Standard Error at Initial Time\n",
    "        _, _, _, se_uk, _ = self.hj_mad.compute_grad_uk(self.x_0_slider.value, self.t_init_slider.value)\n",
    "\n",
    "        self.standard_error_display.value = f\"\"\"\n",
    "            <div style=\"border: 1px solid black; padding: 10px; border-radius: 5px; margin-top: 10px;\">\n",
    "                <h4 style=\"margin: 0;\">Standard Error for u<sub>k</sub> <i>(Variation Of The Sample Mean Between Samples)</i></h4>\n",
    "            <div style=\"font-family: Times New Roman, serif; font-size: 14px;\">\n",
    "                <p><strong>Standard Error = <sup>σ</sup>/<sub>/√n</sub> = {se_uk:.4e}, where</strong>:</p>\n",
    "                    <p style=\"margin-left: 20px;\">• SE is Standard Error.</p>\n",
    "                    <p style=\"margin-left: 20px;\">• σ is the Standard Deviation(depends on δ, t, f and x).</p>\n",
    "                    <p style=\"margin-left: 20px;\">• n is the sample size.</p>\n",
    "            </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "    def update_hj_mad_x0(self,b):\n",
    "        self.hj_mad.x0 = self.x_0_slider.value\n",
    "        self.update_t_threshold_display()\n",
    "        self.plot_hj_mad()\n",
    "\n",
    "    def update_function(self, change):\n",
    "        # Update the selected function based on dropdown selection\n",
    "        if change['new'] == 'Sinc':\n",
    "            intervalx_a, intervalx_b = -20, 20\n",
    "            self.hj_mad.plot_parameters = [intervalx_a, intervalx_b,self.plot_output]\n",
    "            self.hj_mad.f = Sinc_numpy\n",
    "            self.hj_mad.x_true = 4.49341\n",
    "            self.gamma = 0.1259\n",
    "        elif change['new'] == 'Sin':\n",
    "            intervalx_a, intervalx_b = -3.5 * pi, 2.5 * pi\n",
    "            self.hj_mad.plot_parameters = [intervalx_a, intervalx_b,self.plot_output]\n",
    "            self.hj_mad.f = Sin_numpy\n",
    "            self.hj_mad.x_true = -np.pi / 2\n",
    "            self.gamma = None\n",
    "        elif change['new'] == 'MultiMinimaAbsFunc':\n",
    "            intervalx_a, intervalx_b = -15, 15\n",
    "            self.hj_mad.plot_parameters = [intervalx_a, intervalx_b,self.plot_output]\n",
    "            self.hj_mad.f = MultiMinimaAbsFunc_numpy\n",
    "            self.hj_mad.x_true = 2\n",
    "            self.gamma = 1.43457\n",
    "        elif change['new'] == 'DiscontinuousFunc':\n",
    "            intervalx_a, intervalx_b = -15, 15\n",
    "            self.hj_mad.plot_parameters = [intervalx_a, intervalx_b,self.plot_output]\n",
    "            self.hj_mad.f = DiscontinuousFunc_numpy\n",
    "            self.hj_mad.x_true = 2\n",
    "            self.gamma = 7\n",
    "        else:  # change['new'] == 'MultiMinimaFunc'\n",
    "            intervalx_a, intervalx_b = -30, 30\n",
    "            self.hj_mad.plot_parameters = [intervalx_a, intervalx_b,self.plot_output]\n",
    "            self.hj_mad.f = MultiMinimaFunc_numpy\n",
    "            self.hj_mad.x_true = -1.51034568\n",
    "            self.gamma = 1.89777\n",
    "\n",
    "        # Update the slider range for x_0 based on the new function\n",
    "        self.x_0_slider.min = intervalx_a\n",
    "        self.x_0_slider.max = intervalx_b\n",
    "        self.x_0_slider.value = (intervalx_a + intervalx_b) / 2\n",
    "\n",
    "        self.update_t_threshold_display()\n",
    "        self.update_standard_error_display()\n",
    "        self.plot_results_output.clear_output()  # Clear previous results\n",
    "        self.plot_hj_mad()\n",
    "    \n",
    "    def update_fixed_time(self, change):\n",
    "        \"\"\"\n",
    "        Update the fixed time state based on the checkbox.\n",
    "        \"\"\"\n",
    "        self.hj_mad.fixed_time = change['new']\n",
    "        # self.update_standard_error_display()\n",
    "        # self.update_t_threshold_display()\n",
    "\n",
    "    def update_acceleration(self, change):\n",
    "        \"\"\"\n",
    "        Update the accelerated state based on the checkbox.\n",
    "        \"\"\"\n",
    "        self.hj_mad.accelerated = change['new']\n",
    "\n",
    "    def display_sampling(self, change):\n",
    "        \"\"\"\n",
    "        Update the sampling display state based on the checkbox.\n",
    "        \"\"\"\n",
    "        self.hj_mad.sample_bool = change['new']\n",
    "        self.plot_results_output.clear_output()  # Clear previous results\n",
    "        self.plot_hj_mad()\n",
    "\n",
    "    def run(self, animate):\n",
    "        self.plot_results_output.clear_output()  # Clear previous results\n",
    "        # Run optimization with current slider values\n",
    "        print('-------------------------- RUNNING HJ-MAD ---------------------------')\n",
    "        print('For the parameters:')\n",
    "        self.print_slider_values()\n",
    "\n",
    "        _, algorithm_hist = self.hj_mad.run(animate=animate)\n",
    "        \n",
    "        self.plot_results(algorithm_hist)\n",
    "        display(Image(filename=\"MAD_interactive_plot.png\"))\n",
    "\n",
    "    def plot_hj_mad(self):\n",
    "        self.hj_mad.plot(0, self.hj_mad.x0, self.hj_mad.t_vec[0],0)\n",
    "    \n",
    "    def plot_results(self, algorithm_hist):\n",
    "        # Unpack general case and accelerated case histories\n",
    "        non_acc_algorithm_hist = None\n",
    "\n",
    "        if self.hj_mad.accelerated:\n",
    "            self.hj_mad.accelerated = False\n",
    "            _, non_acc_algorithm_hist = self.hj_mad.run(animate=False,plot_bool=False)\n",
    "            _, non_acc_tk_hist, non_acc_xk_error_hist, non_acc_rel_grad_uk_norm_hist, non_acc_fk_hist = non_acc_algorithm_hist\n",
    "            acc_string = ' (Accelerated)'\n",
    "            self.hj_mad.accelerated = True\n",
    "        else:\n",
    "            acc_string = ' (Non-Accelerated)'\n",
    "        \n",
    "        _, tk_hist, xk_error_hist, rel_grad_uk_norm_hist, fk_hist = algorithm_hist\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "\n",
    "        # Error history subplot\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.semilogy(xk_error_hist, label='Error History'+acc_string, color='blue')\n",
    "        if non_acc_algorithm_hist is not None:\n",
    "            plt.semilogy(non_acc_xk_error_hist, label='Error History (Non-Accelerated)', color='orange', linestyle='--')\n",
    "        plt.title('Error History')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Error')\n",
    "        plt.legend()\n",
    "\n",
    "        # f(k) history subplot\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(fk_hist, label='f(k) History'+acc_string, color='blue')\n",
    "        if non_acc_algorithm_hist is not None:\n",
    "            plt.plot(non_acc_fk_hist, label='f(k) History (Non-Accelerated)', color='orange', linestyle='--')\n",
    "        plt.title('f(k) History')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('f(k)')\n",
    "        plt.legend()\n",
    "\n",
    "        # t(k) history subplot\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.semilogy(tk_hist, label='t(k) History'+acc_string, color='blue')\n",
    "        if non_acc_algorithm_hist is not None:\n",
    "            plt.semilogy(non_acc_tk_hist, label='t(k) History (Non-Accelerated)', color='orange', linestyle='--')\n",
    "        plt.title('t(k) History')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('t(k)')\n",
    "        plt.legend()\n",
    "\n",
    "        # Relative gradient norm history subplot\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.loglog(rel_grad_uk_norm_hist, label='Rel. Grad Norm'+acc_string, color='blue')\n",
    "        if non_acc_algorithm_hist is not None:\n",
    "            plt.loglog(non_acc_rel_grad_uk_norm_hist, label='Rel. Grad Norm (Non-Accelerated)', color='orange', linestyle='--')\n",
    "        plt.title('Relative Gradient Norm History')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Relative Gradient Norm')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()  # Adjust the layout\n",
    "        plt.savefig(\"MAD_combined_history_plot.png\", format='png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()  # Free up memory\n",
    "\n",
    "        # Display the latest saved plot\n",
    "        with self.plot_results_output:\n",
    "            clear_output(wait=True)  # Clear previous plot\n",
    "            display(Image(filename=\"MAD_combined_history_plot.png\"))\n",
    "\n",
    "    def reset_plot(self):\n",
    "        \"\"\"Reset the plot and hide the plot results.\"\"\"\n",
    "        self.plot_hj_mad()\n",
    "        self.plot_results_output.clear_output()  # Clear previous results\n",
    "        #self.plot_results_output = None  # Reset the plot results\n",
    "    \n",
    "    def tol_input_update(self, _):\n",
    "        self.hj_mad.tol = self.tol_input.value\n",
    "\n",
    "    def print_slider_values(self):\n",
    "        \"\"\"Print the values of the sliders and selected function in a rotated table format.\"\"\"\n",
    "        function_name = self.function_dropdown.value\n",
    "        slider_values = {\n",
    "            'x_0': self.x_0_slider.value,\n",
    "            't_init': self.t_init_slider.value,\n",
    "            't_max': self.t_max_slider.value,\n",
    "            'delta': self.delta_slider.value,\n",
    "            'int_samples': self.int_samples_slider.value,\n",
    "            'max_iters': self.max_iters_slider.value,\n",
    "            'alpha': self.alpha_slider.value,\n",
    "            't_threshold': self.t_threshold\n",
    "        }\n",
    "\n",
    "        # Create a smaller HTML table in rotated format\n",
    "        html_content = \"<h3>Slider Values and Function Name</h3><table style='border-collapse: collapse; width: 50%; font-size: 14px;'><tr><th style='border: 1px solid black;'><strong>Parameter</strong></th><th style='border: 1px solid black;'><strong>Value</strong></th></tr>\"\n",
    "        \n",
    "        # Add each parameter and its value as a new row\n",
    "        for param, value in slider_values.items():\n",
    "            html_content += f\"<tr><td style='border: 1px solid black;'>{param}</td><td style='border: 1px solid black;'>{value:.2f}</td></tr>\"\n",
    "        \n",
    "        # Add the function name at the end\n",
    "        html_content += f\"<tr><td style='border: 1px solid black;'>Function</td><td style='border: 1px solid black;'>{function_name}</td></tr>\"\n",
    "        html_content += \"</table>\"\n",
    "\n",
    "        # Display the table\n",
    "        display(HTML(html_content))\n",
    "\n",
    "    def create_ui(self):\n",
    "        # Title and Section Headers:\n",
    "        title = HTML(\"<h2>HJ Moreau Adaptive Descent Visualization (in 1D)</h2>\")\n",
    "        internal_parameters = HTML(\"<h3>Internal Parameters:</h3>\")\n",
    "        initial_conditions = HTML(\"<h3>Initial Conditions Parameters:</h3>\")\n",
    "        \n",
    "        # Dropdown to select the function\n",
    "        self.function_dropdown = Dropdown(\n",
    "            options=['Sinc', 'Sin', 'MultiMinima','MultiMinimaAbsFunc', 'DiscontinuousFunc'],\n",
    "            value='MultiMinima',\n",
    "            description='Function:',\n",
    "            tooltip='Select the mathematical function to optimize.'\n",
    "        )\n",
    "        \n",
    "        # Sliders for parameters, initialized with default values\n",
    "        self.x_0_slider = FloatSlider(value=self.hj_mad.x0, min=self.hj_mad.plot_parameters[0], max=self.hj_mad.plot_parameters[1], step=0.01, description=r'x_0:', tooltip='Adjust the initial position.')\n",
    "        self.delta_slider = FloatSlider(value=self.hj_mad.delta, min=0, max=5.0, step=0.005, description='Viscosity, δ:', tooltip='Adjust the viscosity parameter.')\n",
    "        self.int_samples_slider = FloatSlider(value=self.hj_mad.int_samples, min=2, max=1000, step=1, description='Samples, n:', tooltip='Select the number of samples.')\n",
    "        self.t_max_slider = FloatSlider(value=self.hj_mad.t_vec[2], min=self.t_min, max=100, step=0.1, description='Max t, T:', tooltip='Set the maximum time for the optimization.')\n",
    "        self.t_init_slider = FloatSlider(value=self.hj_mad.t_vec[0], min=self.t_min, max=100, step=0.1, description='Initial t, t₀:', tooltip='Set the initial time for the optimization.')\n",
    "        self.max_iters_slider = FloatSlider(value=self.hj_mad.max_iters, min=1, max=100, step=1, description='Max Iter., N:', tooltip='Set the maximum number of iterations.')\n",
    "        self.alpha_slider = FloatSlider(value=self.hj_mad.alpha, min=0.01, max=1.99, step=0.01, description='Step Size, α:', tooltip='Adjust the step size for optimization.')\n",
    "        self.momentum_slider = FloatSlider(value=self.hj_mad.momentum, min=0.01, max=2, step=0.01, description='Momentum:', tooltip='Adjust the momentum for optimization.')\n",
    "        \n",
    "        # Value input for tolerence\n",
    "        self.tol_input = FloatText(value=self.hj_mad.tol, description='tol:', tooltip='Set the tolerence for optimization.')\n",
    "        self.plot_hj_mad()\n",
    "\n",
    "        # Checkbox for fixed time and acceleration\n",
    "        self.fixed_time_checkbox = Checkbox(value=False, description='Fixed Time', tooltip='Check to use fixed time for optimization.')\n",
    "        self.acceleration_checkbox = Checkbox(value=False, description='Acceleration', tooltip='Check to use Accelerated GD for optimization.')\n",
    "        self.sample_bool_checkbox = Checkbox(value=False, description='Display Samples', tooltip='Check to use Display Sampling.')\n",
    "\n",
    "        # Buttons to run optimization\n",
    "        self.run_button = Button(description='Run Optimization', tooltip='Start the optimization process.')\n",
    "        self.animation_button = Button(description='Run Animation', tooltip='Start the animation of the optimization process.')\n",
    "        self.reset_plot_button = Button(description='Reset Plot', tooltip='Reset the plot to the initial state.')\n",
    "\n",
    "        # Bind slider changes to specific update methods\n",
    "        self.delta_slider.observe(self.update_hj_mad_delta, names='value')\n",
    "        self.int_samples_slider.observe(self.update_hj_mad_int_samples, names='value')\n",
    "        self.t_init_slider.observe(self.update_hj_mad_t_init, names='value')\n",
    "        self.t_max_slider.observe(self.update_hj_mad_t_max, names='value')\n",
    "        self.max_iters_slider.observe(self.update_hj_mad_max_iters, names='value')\n",
    "        self.alpha_slider.observe(self.update_hj_mad_alpha, names='value')\n",
    "        self.momentum_slider.observe(self.update_hj_mad_momentum, names='value')\n",
    "        self.x_0_slider.observe(self.update_hj_mad_x0, names='value')\n",
    "\n",
    "        # Bind tolerence input changes to specific update methods\n",
    "        self.tol_input.observe(self.tol_input_update, names='value')\n",
    "\n",
    "        # Dropdown event listener to update the selected function\n",
    "        self.function_dropdown.observe(self.update_function, names='value')\n",
    "\n",
    "        # Checkbox event listener to update the fixed time state\n",
    "        self.fixed_time_checkbox.observe(self.update_fixed_time, names='value')\n",
    "        self.acceleration_checkbox.observe(self.update_acceleration, names='value')\n",
    "        self.sample_bool_checkbox.observe(self.display_sampling, names='value')\n",
    "        \n",
    "        # Initialize t_threshold_display and standard_error_display\n",
    "        self.t_threshold_display = HTML(\"\")\n",
    "        self.standard_error_display = HTML(\"\")\n",
    "        self.update_t_threshold_display()\n",
    "        self.update_standard_error_display()\n",
    "\n",
    "        # Bind button clicks to the respective methods\n",
    "        self.run_button.on_click(lambda b: self.run(animate=False))\n",
    "        self.animation_button.on_click(lambda b: self.run(animate=True))\n",
    "        self.reset_plot_button.on_click(lambda b: self.reset_plot())\n",
    "\n",
    "        # Display the UI\n",
    "        ui = VBox([title, internal_parameters, \n",
    "                HBox([self.function_dropdown, self.tol_input]),\n",
    "                HBox([self.delta_slider, self.int_samples_slider, self.t_max_slider]), \n",
    "                HBox([self.max_iters_slider, self.alpha_slider,self.momentum_slider]),\n",
    "                HBox([self.sample_bool_checkbox, self.fixed_time_checkbox, self.acceleration_checkbox]),\n",
    "                initial_conditions, \n",
    "                HBox([self.t_init_slider, self.x_0_slider]),\n",
    "                HBox([self.standard_error_display, self.t_threshold_display]),\n",
    "                HBox([self.run_button, self.animation_button,self.reset_plot_button]), # instructions,\n",
    "                HBox([self.plot_output,self.plot_results_output])])  # Add plot output to the UI\n",
    "        display(ui)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91e45f836a145abaaf03a24d6848525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>HJ Moreau Adaptive Descent Visualization (in 1D)</h2>'), HTML(value='<h3>Intern…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "UI= HJ_MAD_UI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
