{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- RUNNING HJ-MAD-LS Algorithm ---------------------------\n",
      "dimension =  150 n_samples =  10\n",
      "[  0]: fk = 8.79e+01 | delta = 1.00e-01\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 32.724586486816406 | f(xk): 87.90498352050781\n",
      "    No improvement from line search | f(prox_ls): tensor([[54.8676]])\n",
      "[  1]: fk = 2.17e+01 | delta = 1.00e-01\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 2.495229959487915 | f(xk): 21.703598022460938\n",
      "    No improvement from line search | f(prox_ls): tensor([[9.4499]])\n",
      "[  2]: fk = 2.75e+00 | delta = 1.00e-01\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 0.5520502328872681 | f(xk): 2.7520530223846436\n",
      "    No improvement from line search | f(prox_ls): tensor([[1.0807]])\n",
      "[  3]: fk = 1.33e+00 | delta = 1.00e-01\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.636005699634552 | f(xk): 1.3287668228149414\n",
      "    No improvement from line search | f(prox_ls): tensor([[1.0793]])\n",
      "[  4]: fk = 3.71e-01 | delta = 1.00e-01\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 2.9744391441345215 | f(xk): 0.37061989307403564\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.3623]])\n",
      "[  5]: fk = 3.72e-01 | delta = 8.00e-02\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 2.481987953186035 | f(xk): 0.3722957670688629\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.3723]])\n",
      "[  6]: fk = 3.71e-01 | delta = 6.40e-02\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.3153756856918335 | f(xk): 0.3714957535266876\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.3555]])\n",
      "[  7]: fk = 3.26e-01 | delta = 6.40e-02\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.6396037936210632 | f(xk): 0.32558682560920715\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.3227]])\n",
      "[  8]: fk = 3.15e-01 | delta = 5.12e-02\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 0.23242732882499695 | f(xk): 0.3148787021636963\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.3092]])\n",
      "[  9]: fk = 2.67e-01 | delta = 5.12e-02\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 2.061086893081665 | f(xk): 0.266571044921875\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.2578]])\n",
      "[ 10]: fk = 2.18e-01 | delta = 4.10e-02\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 1.7469919919967651 | f(xk): 0.2180546522140503\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.1721]])\n",
      "[ 11]: fk = 1.75e-01 | delta = 3.28e-02\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 0.28428518772125244 | f(xk): 0.17454257607460022\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.1745]])\n",
      "[ 12]: fk = 1.73e-01 | delta = 2.62e-02\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 1.86077880859375 | f(xk): 0.1726178377866745\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.1720]])\n",
      "[ 13]: fk = 1.72e-01 | delta = 2.10e-02\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 1.0004773139953613 | f(xk): 0.17192049324512482\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.1533]])\n",
      "[ 14]: fk = 1.55e-01 | delta = 1.68e-02\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.3595334589481354 | f(xk): 0.15469221770763397\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.1516]])\n",
      "[ 15]: fk = 1.51e-01 | delta = 1.34e-02\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.5841655135154724 | f(xk): 0.1507694125175476\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.1040]])\n",
      "[ 16]: fk = 1.07e-01 | delta = 1.07e-02\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.4477849304676056 | f(xk): 0.10656315088272095\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0983]])\n",
      "[ 17]: fk = 9.72e-02 | delta = 8.59e-03\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.8837626576423645 | f(xk): 0.09723471850156784\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0945]])\n",
      "[ 18]: fk = 9.43e-02 | delta = 6.87e-03\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.32185840606689453 | f(xk): 0.09428718686103821\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0942]])\n",
      "[ 19]: fk = 9.41e-02 | delta = 5.50e-03\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.13507336378097534 | f(xk): 0.09409795701503754\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0940]])\n",
      "[ 20]: fk = 9.40e-02 | delta = 4.40e-03\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.14120958745479584 | f(xk): 0.09398534893989563\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0934]])\n",
      "[ 21]: fk = 9.35e-02 | delta = 3.52e-03\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.1636270135641098 | f(xk): 0.09346827864646912\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0924]])\n",
      "[ 22]: fk = 9.25e-02 | delta = 2.81e-03\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.235728457570076 | f(xk): 0.0924587994813919\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0866]])\n",
      "[ 23]: fk = 8.67e-02 | delta = 2.25e-03\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.2349352240562439 | f(xk): 0.08671268820762634\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0860]])\n",
      "[ 24]: fk = 8.59e-02 | delta = 1.80e-03\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.22521276772022247 | f(xk): 0.08594857901334763\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0857]])\n",
      "[ 25]: fk = 8.57e-02 | delta = 1.44e-03\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 0.11569826304912567 | f(xk): 0.08568830788135529\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0854]])\n",
      "[ 26]: fk = 8.54e-02 | delta = 1.15e-03\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.09392315149307251 | f(xk): 0.08537331223487854\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0844]])\n",
      "[ 27]: fk = 8.44e-02 | delta = 9.22e-04\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.11242416501045227 | f(xk): 0.08444595336914062\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0844]])\n",
      "[ 28]: fk = 8.43e-02 | delta = 7.38e-04\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.08952763676643372 | f(xk): 0.08434644341468811\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0838]])\n",
      "[ 29]: fk = 8.39e-02 | delta = 5.90e-04\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.07671213895082474 | f(xk): 0.08388213813304901\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0818]])\n",
      "[ 30]: fk = 7.66e-02 | delta = 5.90e-04\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.09849899262189865 | f(xk): 0.07661564648151398\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0757]])\n",
      "[ 31]: fk = 7.58e-02 | delta = 4.72e-04\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.09305715560913086 | f(xk): 0.07576213032007217\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0757]])\n",
      "[ 32]: fk = 7.56e-02 | delta = 3.78e-04\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.07659809291362762 | f(xk): 0.07563424110412598\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0734]])\n",
      "[ 33]: fk = 7.35e-02 | delta = 3.02e-04\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.08518657088279724 | f(xk): 0.07351650297641754\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0735]])\n",
      "[ 34]: fk = 7.34e-02 | delta = 2.42e-04\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.08843183517456055 | f(xk): 0.07338247448205948\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0733]])\n",
      "[ 35]: fk = 7.33e-02 | delta = 1.93e-04\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.08216659724712372 | f(xk): 0.07333360612392426\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0733]])\n",
      "[ 36]: fk = 7.33e-02 | delta = 1.55e-04\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.0774899497628212 | f(xk): 0.0732700377702713\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0730]])\n",
      "[ 37]: fk = 7.30e-02 | delta = 1.24e-04\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.07236779481172562 | f(xk): 0.07301605492830276\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0726]])\n",
      "[ 38]: fk = 7.22e-02 | delta = 1.24e-04\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.07914109528064728 | f(xk): 0.07217258214950562\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0715]])\n",
      "[ 39]: fk = 7.17e-02 | delta = 9.90e-05\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.07061771303415298 | f(xk): 0.07168971747159958\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0713]])\n",
      "[ 40]: fk = 7.06e-02 | delta = 9.90e-05\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.06953456252813339 | f(xk): 0.07058369368314743\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0699]])\n",
      "[ 41]: fk = 6.93e-02 | delta = 9.90e-05\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.06552747637033463 | f(xk): 0.06934170424938202\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0668]])\n",
      "[ 42]: fk = 6.53e-02 | delta = 9.90e-05\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.06457943469285965 | f(xk): 0.0652928352355957\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0650]])\n",
      "[ 43]: fk = 6.45e-02 | delta = 9.90e-05\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.0663624256849289 | f(xk): 0.06445596367120743\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0638]])\n",
      "[ 44]: fk = 6.39e-02 | delta = 7.92e-05\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.06413882225751877 | f(xk): 0.06393051147460938\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0627]])\n",
      "[ 45]: fk = 6.27e-02 | delta = 6.34e-05\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.058600522577762604 | f(xk): 0.06270784884691238\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0602]])\n",
      "[ 46]: fk = 5.86e-02 | delta = 6.34e-05\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.060825470834970474 | f(xk): 0.05858079344034195\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0582]])\n",
      "[ 47]: fk = 5.80e-02 | delta = 5.07e-05\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.05874370038509369 | f(xk): 0.05802764743566513\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0577]])\n",
      "[ 48]: fk = 5.76e-02 | delta = 4.06e-05\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.056274089962244034 | f(xk): 0.05763731896877289\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0571]])\n",
      "[ 49]: fk = 5.64e-02 | delta = 4.06e-05\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.059979189187288284 | f(xk): 0.05635940656065941\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0560]])\n",
      "[ 50]: fk = 5.59e-02 | delta = 3.25e-05\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.06055133044719696 | f(xk): 0.0558856725692749\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0558]])\n",
      "[ 51]: fk = 5.58e-02 | delta = 2.60e-05\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.05530855059623718 | f(xk): 0.05576889216899872\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0554]])\n",
      "[ 52]: fk = 5.53e-02 | delta = 2.60e-05\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.05477740243077278 | f(xk): 0.05525045469403267\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0550]])\n",
      "[ 53]: fk = 5.47e-02 | delta = 2.60e-05\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.057483263313770294 | f(xk): 0.0547051727771759\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0542]])\n",
      "[ 54]: fk = 5.42e-02 | delta = 2.08e-05\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.05386412516236305 | f(xk): 0.05420239269733429\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0536]])\n",
      "[ 55]: fk = 5.36e-02 | delta = 2.08e-05\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 0.05556921660900116 | f(xk): 0.0536147803068161\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0536]])\n",
      "[ 56]: fk = 5.36e-02 | delta = 1.66e-05\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.053975868970155716 | f(xk): 0.05357801914215088\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0532]])\n",
      "[ 57]: fk = 5.32e-02 | delta = 1.33e-05\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.05490671470761299 | f(xk): 0.05323132127523422\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0532]])\n",
      "[ 58]: fk = 5.32e-02 | delta = 1.06e-05\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.054087214171886444 | f(xk): 0.05320954695343971\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0532]])\n",
      "[ 59]: fk = 5.32e-02 | delta = 8.51e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.052357349544763565 | f(xk): 0.053163960576057434\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0528]])\n",
      "[ 60]: fk = 5.24e-02 | delta = 8.51e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.05310680717229843 | f(xk): 0.05242747440934181\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0524]])\n",
      "[ 61]: fk = 5.24e-02 | delta = 6.81e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.05273972451686859 | f(xk): 0.052358582615852356\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0523]])\n",
      "[ 62]: fk = 5.23e-02 | delta = 5.44e-06\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.052376676350831985 | f(xk): 0.0523255430161953\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0523]])\n",
      "[ 63]: fk = 5.23e-02 | delta = 4.36e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.052299804985523224 | f(xk): 0.052312396466732025\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0523]])\n",
      "[ 64]: fk = 5.23e-02 | delta = 4.36e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.052105654031038284 | f(xk): 0.052295178174972534\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0521]])\n",
      "[ 65]: fk = 5.21e-02 | delta = 4.36e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.052201658487319946 | f(xk): 0.052097417414188385\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0520]])\n",
      "[ 66]: fk = 5.20e-02 | delta = 3.48e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.05135403946042061 | f(xk): 0.052048150449991226\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0517]])\n",
      "[ 67]: fk = 5.14e-02 | delta = 3.48e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.05125860124826431 | f(xk): 0.05139504745602608\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0513]])\n",
      "[ 68]: fk = 5.12e-02 | delta = 3.48e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.051074374467134476 | f(xk): 0.05119162052869797\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0510]])\n",
      "[ 69]: fk = 5.09e-02 | delta = 3.48e-06\n",
      "    Samples taken into account by softmax: 5\n",
      "    f(prox): 0.05118178948760033 | f(xk): 0.05094947665929794\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0509]])\n",
      "[ 70]: fk = 5.09e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.050649333745241165 | f(xk): 0.05093549191951752\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0508]])\n",
      "[ 71]: fk = 5.07e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.050508055835962296 | f(xk): 0.05066889896988869\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0506]])\n",
      "[ 72]: fk = 5.05e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.049969300627708435 | f(xk): 0.05050714313983917\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0502]])\n",
      "[ 73]: fk = 5.00e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.04979284107685089 | f(xk): 0.04995846375823021\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0499]])\n",
      "[ 74]: fk = 4.98e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.04970590025186539 | f(xk): 0.049797188490629196\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0497]])\n",
      "[ 75]: fk = 4.97e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.0492919459939003 | f(xk): 0.04968703165650368\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0495]])\n",
      "[ 76]: fk = 4.93e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.04916583001613617 | f(xk): 0.049315109848976135\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0492]])\n",
      "[ 77]: fk = 4.92e-02 | delta = 2.79e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.04921645671129227 | f(xk): 0.049167729914188385\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0492]])\n",
      "[ 78]: fk = 4.92e-02 | delta = 2.23e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.04888875409960747 | f(xk): 0.0491623692214489\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0490]])\n",
      "[ 79]: fk = 4.89e-02 | delta = 2.23e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.04874301329255104 | f(xk): 0.048899464309215546\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0488]])\n",
      "[ 80]: fk = 4.88e-02 | delta = 2.23e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.04842182621359825 | f(xk): 0.048755187541246414\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0486]])\n",
      "[ 81]: fk = 4.84e-02 | delta = 2.23e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.048553552478551865 | f(xk): 0.04844563081860542\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0482]])\n",
      "[ 82]: fk = 4.82e-02 | delta = 1.78e-06\n",
      "    Samples taken into account by softmax: 4\n",
      "    f(prox): 0.04828566685318947 | f(xk): 0.04821648448705673\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0482]])\n",
      "[ 83]: fk = 4.82e-02 | delta = 1.43e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.047851573675870895 | f(xk): 0.04818149656057358\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0480]])\n",
      "[ 84]: fk = 4.78e-02 | delta = 1.43e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.047624338418245316 | f(xk): 0.047846898436546326\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0478]])\n",
      "[ 85]: fk = 4.76e-02 | delta = 1.43e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.04738973453640938 | f(xk): 0.047645363956689835\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0475]])\n",
      "[ 86]: fk = 4.74e-02 | delta = 1.43e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.04729892686009407 | f(xk): 0.04737934097647667\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0473]])\n",
      "[ 87]: fk = 4.73e-02 | delta = 1.43e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.04743192344903946 | f(xk): 0.04729078337550163\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0473]])\n",
      "[ 88]: fk = 4.73e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.04714057594537735 | f(xk): 0.0472690612077713\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0472]])\n",
      "[ 89]: fk = 4.71e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.046896401792764664 | f(xk): 0.04714775085449219\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0470]])\n",
      "[ 90]: fk = 4.69e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.04664525389671326 | f(xk): 0.04688165709376335\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0468]])\n",
      "[ 91]: fk = 4.66e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.046539805829524994 | f(xk): 0.04663814231753349\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0466]])\n",
      "[ 92]: fk = 4.65e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.04628311097621918 | f(xk): 0.04651894420385361\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0464]])\n",
      "[ 93]: fk = 4.63e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.046050358563661575 | f(xk): 0.04629875347018242\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0462]])\n",
      "[ 94]: fk = 4.61e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 3\n",
      "    f(prox): 0.04588191211223602 | f(xk): 0.04605477303266525\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0459]])\n",
      "[ 95]: fk = 4.59e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.045760296285152435 | f(xk): 0.04585995525121689\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0458]])\n",
      "[ 96]: fk = 4.57e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.0456128865480423 | f(xk): 0.04573049396276474\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0457]])\n",
      "[ 97]: fk = 4.56e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 1\n",
      "    f(prox): 0.045573197305202484 | f(xk): 0.04563688114285469\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0456]])\n",
      "[ 98]: fk = 4.56e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.0454801544547081 | f(xk): 0.04556172341108322\n",
      "    No improvement from line search | f(prox_ls): tensor([[0.0455]])\n",
      "[ 99]: fk = 4.55e-02 | delta = 1.14e-06\n",
      "    Samples taken into account by softmax: 2\n",
      "    f(prox): 0.04551037773489952 | f(xk): 0.04548802226781845\n",
      "    Improvement from line search | f(prox_ls): tensor([[0.0455]])\n",
      "[100]: fk = 4.55e-02 | delta = 9.13e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 148\u001b[0m\n\u001b[1;32m    145\u001b[0m new_parameters, loss, iterations \u001b[38;5;241m=\u001b[39m HJ_MAD_alg\u001b[38;5;241m.\u001b[39mrun(f, parameter_vector)  \u001b[38;5;66;03m# Run HJ_MAD to optimize the model parameters\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Update the model parameters with the optimized values\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Print the loss before and after optimization\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss before: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_old\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss after: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Iterations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m, in \u001b[0;36mShallowNet.set_parameters\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m     66\u001b[0m param_size \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mnumel() \n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if param_size.len() == 1:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#new_param_values = parameters[0, offset:offset + param_size]\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m new_param_values \u001b[38;5;241m=\u001b[39m \u001b[43mparameters\u001b[49m[offset:offset \u001b[38;5;241m+\u001b[39m param_size]\n\u001b[1;32m     71\u001b[0m new_param_values \u001b[38;5;241m=\u001b[39m new_param_values\u001b[38;5;241m.\u001b[39mview(param\u001b[38;5;241m.\u001b[39mshape)  \n\u001b[1;32m     72\u001b[0m param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(new_param_values)  \n",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m, in \u001b[0;36mShallowNet.set_parameters\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m     66\u001b[0m param_size \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mnumel() \n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if param_size.len() == 1:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#new_param_values = parameters[0, offset:offset + param_size]\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m new_param_values \u001b[38;5;241m=\u001b[39m \u001b[43mparameters\u001b[49m[offset:offset \u001b[38;5;241m+\u001b[39m param_size]\n\u001b[1;32m     71\u001b[0m new_param_values \u001b[38;5;241m=\u001b[39m new_param_values\u001b[38;5;241m.\u001b[39mview(param\u001b[38;5;241m.\u001b[39mshape)  \n\u001b[1;32m     72\u001b[0m param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(new_param_values)  \n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv38/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv38/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from hj_mad_ls import HJ_MD_LS\n",
    "\n",
    "# Hyperparameters\n",
    "n_neurons = 50  # Number of neurons in the shallow network\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "# Generate data\n",
    "no_of_samples = 500\n",
    "noise_level = 1e-3\n",
    "x = np.linspace(0, 2 * np.pi, no_of_samples)\n",
    "y = np.sin(x) + noise_level * np.random.randn(*x.shape)  # Add noise to the samples\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(1)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the shallow neural network\n",
    "class ShallowNet(nn.Module):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(ShallowNet, self).__init__()\n",
    "        self.linear = nn.Linear(1, n_neurons)\n",
    "        self.coeffs = nn.Parameter(torch.randn(n_neurons, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)      # Compute w_j * x + b_j\n",
    "        x = self.relu(x)        # Apply ReLU activation\n",
    "        x = x @ self.coeffs     # Compute sum of c_j * ReLU(...)\n",
    "        return x\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\"\n",
    "        Set model parameters from the flattened parameter vector.\n",
    "        This method updates the model's parameters from a single flattened tensor.\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        for param in parameters:\n",
    "            param_size = param.numel() \n",
    "            # if param_size.len() == 1:\n",
    "            #new_param_values = parameters[0, offset:offset + param_size]\n",
    "            # else:\n",
    "            new_param_values = parameters[offset:offset + param_size]\n",
    "            new_param_values = new_param_values.view(param.shape)  \n",
    "            param.data.copy_(new_param_values)  \n",
    "            offset += param_size  \n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = ShallowNet(n_neurons)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# HJ_MAD hyperparameters\n",
    "delta = 0.1\n",
    "t = 1\n",
    "int_samples = int(10)\n",
    "max_iters = int(1e2)\n",
    "f_tol = 1e-5\n",
    "sat_tol = 1e-5\n",
    "delta_dampener=0.8\n",
    "beta=0.1\n",
    "\n",
    "# Use HJ_MAD to optimize the model parameters\n",
    "HJ_MAD_alg = HJ_MD_LS(delta=delta, t=t, int_samples=int_samples, max_iters=max_iters, f_tol=f_tol,sat_tol=sat_tol,delta_dampener=delta_dampener,beta=beta,verbose=True)\n",
    "\n",
    "# Define the function f (e.g., a loss function based on the model's predictions)\n",
    "def Objective_function(x, model, inputs, targets):\n",
    "    '''\n",
    "    Input:\n",
    "        - tensor x is of shape (samples, n_features)\n",
    "    Output:\n",
    "        - loss values tensor of shape (samples, 1)\n",
    "    '''\n",
    "    n_features = x.shape[1]\n",
    "    n_samples = x.shape[0]\n",
    "    \n",
    "    # Initialize the list to store individual sample losses\n",
    "    sample_losses = []\n",
    "\n",
    "    # Loop over each sample and compute the loss\n",
    "    for i in range(n_samples):\n",
    "        # Extract model parameters for the current sample (flattened)\n",
    "        model_params = x[i, :]  # Take the i-th sample from the flattened parameter vector\n",
    "        \n",
    "        # Set the model parameters using the current flattened parameters\n",
    "        model.set_parameters(model_params)  # Set the model parameters\n",
    "        \n",
    "        # Forward pass: Get the output of the model for the given inputs\n",
    "        outputs = model(inputs)#[i:i+1])  # Take a single input for each sample\n",
    "        \n",
    "        # Calculate the loss for the current sample\n",
    "        loss = criterion(outputs, targets)#[i:i+1])  # Calculate the loss for the i-th sample\n",
    "        \n",
    "        # Store the loss for the current sample\n",
    "        sample_losses.append(loss.item())  # Append loss to list\n",
    "    \n",
    "    # Convert the list of sample losses to a tensor and return\n",
    "    return torch.tensor(sample_losses).view(-1, 1)\n",
    "\n",
    "# Training loop: Iterate through the epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Iterate through the dataset in batches\n",
    "    for inputs, targets in dataloader:\n",
    "        # Define f\n",
    "        def f(x):\n",
    "            return Objective_function(x, model, inputs, targets)\n",
    "        \n",
    "        # Get the model parameters as a flattened tensor\n",
    "        parameters = list(model.parameters())\n",
    "        parameter_vector = torch.cat([param.flatten() for param in parameters])\n",
    "        parameter_vector = parameter_vector.unsqueeze(0) # shape (1, num_features)\n",
    "\n",
    "        # Compute Current Loss\n",
    "        loss_old = f(parameter_vector)  # Compute the loss for the current parameters\n",
    "\n",
    "        # Run HJ_MAD to optimize the model parameters\n",
    "        new_parameters, loss, iterations = HJ_MAD_alg.run(f, parameter_vector)  # Run HJ_MAD to optimize the model parameters\n",
    "\n",
    "        # Update the model parameters with the optimized values\n",
    "        model.set_parameters(new_parameters)\n",
    "\n",
    "        # Print the loss before and after optimization\n",
    "        print(f'Loss before: {loss_old.item():.4f} | Loss after: {loss.item():.4f} | Iterations: {iterations}')\n",
    "        \n",
    "    # Print the loss every 100 epochs for monitoring\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Visualise the learned function\n",
    "plt.figure()\n",
    "plt.plot(x, y, label='True function')\n",
    "plt.plot(x, model(x_tensor).detach().numpy(), '--', label='Learned function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0130\n",
      "Epoch [200/1000], Loss: 0.0031\n",
      "Epoch [300/1000], Loss: 0.0014\n",
      "Epoch [400/1000], Loss: 0.0024\n",
      "Epoch [500/1000], Loss: 0.0007\n",
      "Epoch [600/1000], Loss: 0.0029\n",
      "Epoch [700/1000], Loss: 0.0159\n",
      "Epoch [800/1000], Loss: 0.0010\n",
      "Epoch [900/1000], Loss: 0.0018\n",
      "Epoch [1000/1000], Loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "n_neurons = 50  # Number of neurons in the shallow network\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "# Generate data\n",
    "no_of_samples = 500\n",
    "noise_level = 1e-3\n",
    "x = np.linspace(0, 2 * np.pi, no_of_samples)\n",
    "y = np.sin(x) + noise_level * np.random.randn(*x.shape)  # Add noise to the samples\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(1)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the shallow neural network\n",
    "class ShallowNet(nn.Module):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(ShallowNet, self).__init__()\n",
    "        self.linear = nn.Linear(1, n_neurons)\n",
    "        self.coeffs = nn.Parameter(torch.randn(n_neurons, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)      # Compute w_j * x + b_j\n",
    "        x = self.relu(x)        # Apply ReLU activation\n",
    "        x = x @ self.coeffs     # Compute sum of c_j * ReLU(...)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = ShallowNet(n_neurons)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Visualise the learned function\n",
    "plt.figure()\n",
    "plt.plot(x, y, label='True function')\n",
    "plt.plot(x, model(x_tensor).detach().numpy(), '--', label='Learned function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
