{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPOilvdqgxGu"
   },
   "source": [
    "# This notebook is based on the paper: \"Global-Convergence-Nonconvex-Optimization\". \n",
    "\n",
    "The aim of this project is to find the global solution to  \n",
    "\\begin{equation}\n",
    "  \\min_{x \\in \\mathbb{R}^n} f(x).\n",
    "\\end{equation}\n",
    "\n",
    "To obtain a global minimizer, the main idea is to minimize the Moreau Envelop instead, which \"convexifies\" the original function. To make the Moreau envelope tractable, we use connections to Hamilton-Jacobi Equations via the Cole-Hopf and Hopf-Lax formulas to efficiently compute the gradients of the Moreau envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdiGOuXQA8qO",
    "outputId": "9d09c67a-aa8a-4138-9582-f52a98dc3a32"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from typing import Optional \n",
    "\n",
    "epsilon_double = np.finfo(np.float64).eps\n",
    "\n",
    "from test_functions import Griewank, AlpineN1, Drop_Wave, Levy, Rastrigin, Ackley\n",
    "from test_functions import Griewank_numpy, AlpineN1_numpy, Drop_Wave_numpy, Levy_numpy, Rastrigin_numpy, Ackley_numpy\n",
    "\n",
    "from test_functions import MultiMinimaFunc, MultiMinimaAbsFunc\n",
    "from test_functions import MultiMinimaFunc_numpy, MultiMinimaAbsFunc_numpy\n",
    "\n",
    "seed   = 30\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq1zNUTPg1JJ"
   },
   "source": [
    "### Create Class for Hamilton-Jacobi Moreau Adaptive Descent (HJ_MAD)\n",
    "\n",
    "The Moreau envelop of $f$ is given by\n",
    "\\begin{equation}\n",
    "  u(x,t) \\triangleq \\inf_{z\\in \\mathbb{R}^n} f(z) + \\dfrac{1}{2t}\\|z-x\\|^2.\n",
    "\\end{equation}\n",
    "\n",
    "We leverage the fact that the solution to the Moreau envelope above satisfies the Hamilton-Jacobi Equation\n",
    "\\begin{equation}\n",
    "  \\begin{split}\n",
    "    u_t^\\delta  + \\frac{1}{2}\\|Du^\\delta  \\|^2 \\ = \\frac{\\delta}{2} \\Delta u^\\delta \\qquad &\\text{ in }  \\mathbb{R}^n\\times (0,T]\n",
    "    \\\\\n",
    "    u = f \\qquad &\\text{ in } \\mathbb{R}^n\\times \\{t = 0\\}\n",
    "  \\end{split}\n",
    "\\end{equation}\n",
    "when $\\delta = 0$. \n",
    "\n",
    "By adding a viscous term ($\\delta > 0$), we are able to approximate the solution to the HJ equation using the Cole-Hopf formula to obtain\n",
    "\\begin{equation}\n",
    "  u^\\delta(x,t) = - \\delta \\ln\\Big(\\Phi_t * \\exp(-f/\\delta)\\Big)(x) = - \\delta \\ln \\int_{\\mathbb{R}^n} \\Phi(x-y,t)  \\exp\\left(\\frac{-f(y)}{\\delta}\\right) dy \n",
    "\\end{equation}\n",
    "where \n",
    "\\begin{equation}\n",
    "  \\Phi(x,t) = \\frac{1}{{(4\\pi \\delta t)}^{n/2}} \\exp{\\frac{-\\|x\\|^2}{4\\delta t}}. \n",
    "\\end{equation}\n",
    "This allows us to write the Moreau Envelope (and its gradient) explicitly as an expectation. In this case, we compute the gradient as\n",
    "\\begin{equation}\n",
    "  \\nabla u^\\delta(x,t) = \\dfrac{1}{t}\\cdot  \\dfrac{\\mathbb{E}_{y\\sim  \\mathbb{P}_{x,t}}\\left[(x-y) \\exp\\left(-\\delta^{-1}\\tilde{f}(y)\\right) \\right]}\n",
    "    {\\mathbb{E}_{y\\sim  \\mathbb{P}_{x,t}}\\left[ \\exp\\left(-\\delta^{-1} \\tilde{f}(y)\\right) \\right]}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLVImqaPe-ph"
   },
   "source": [
    "### Define classes for HJ-MD-LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hj_md_ls import HJ_MD_LS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cb--RgyjfPAq"
   },
   "source": [
    "### Set up hyperparameters for HJ-MAD for different functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbHcFJ3e6Qfa"
   },
   "outputs": [],
   "source": [
    "# # Default values\n",
    "delta         = 5e-2\n",
    "max_iters     = int(1e4) #int(1e5)\n",
    "tol           = 5e-3#7e-4\n",
    "\n",
    "\n",
    "# Set the number of trials to run\n",
    "avg_trials = 1\n",
    "sat_tol = 1e-8\n",
    "\n",
    "# # # def f(x):\n",
    "# # #   return MultiMinimaFunc(x)\n",
    "# # # def f_numpy(x):\n",
    "# # #   return MultiMinimaFunc_numpy(x)\n",
    "# # # ax_bry  = 30\n",
    "# # # f_name  = 'MultiMinimaFunc'\n",
    "# # # dim = 1; int_samples = int(100);\n",
    "# # # x0      = -30*torch.ones(dim, dtype=torch.double)\n",
    "# # # x_true  = -1.51034569*torch.ones(dim, dtype=torch.double)\n",
    "\n",
    "# # # delta         = 0.1\n",
    "# # # max_iters     = int(100)\n",
    "# # # tol           = 1e-3\n",
    "# # # momentum = 0.5\n",
    "\n",
    "# # # theta         = 1.0 # note: larger theta => easier to increase time\n",
    "# # # beta          = 0.0\n",
    "# # # t_min     = 1e-1\n",
    "# # # t_max     = 300\n",
    "# # # t_init    = 220\n",
    "# # # alpha     = 0.1\n",
    "# # # eta_min = 0.99\n",
    "# # # eta_plus = 5.0\n",
    "# # # eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "\n",
    "# # # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Griewank(x)\n",
    "# def f_numpy(x):\n",
    "#   return Griewank_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Griewank'\n",
    "# dim = 2; int_samples = int(10);\n",
    "# int_samples_line = int(100)\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "\n",
    "# max_iters     = int(1e5)\n",
    "\n",
    "# delta         = 1e-6 #1e-6\n",
    "\n",
    "# tol           = 5e-3\n",
    "\n",
    "# t    = 1e-2/delta\n",
    "\n",
    "\n",
    "\n",
    "# # # ---------------------------------------------------------------------------------------------------- To Test:\n",
    "\n",
    "# avg_trials = 1\n",
    "# max_iters     = int(1e5)\n",
    "\n",
    "# def f(x):\n",
    "#   return Griewank(x)\n",
    "# def f_numpy(x):\n",
    "#   return Griewank_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Griewank'\n",
    "# dim = 500; int_samples = int(10)\n",
    "# int_samples_line = int(1000)\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "# rescale0      = 2**(-13)\n",
    "# delta         = 1e-6 #1e-6\n",
    "\n",
    "# tol           = 5e-3\n",
    "\n",
    "# t    = 1e-2/delta\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Drop_Wave(x)\n",
    "# def f_numpy(x):\n",
    "#   return Drop_Wave_numpy(x)\n",
    "# ax_bry  = 20\n",
    "\n",
    "# f_name  = 'Drop_Wave'\n",
    "# rescale0      = 1\n",
    "# dim = 2; int_samples = int(100)\n",
    "# int_samples_line = int(100)\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "# delta         = 1e-4\n",
    "\n",
    "# t = int(2e1)/delta\n",
    "\n",
    "\n",
    "# # # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return AlpineN1(x)\n",
    "# def f_numpy(x):\n",
    "#   return AlpineN1_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'AlpineN1'\n",
    "\n",
    "# dim = 2; int_samples = int(10000)\n",
    "# int_samples_line = int(1000)\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "# delta         = 5e-4\n",
    "\n",
    "# t_max     = int(2e1)/delta\n",
    "# t = t_max\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "# avg_trials = 3\n",
    "# def f(x):\n",
    "#   return Levy(x)\n",
    "# def f_numpy(x):\n",
    "#   return Levy_numpy(x)\n",
    "\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Levy'\n",
    "\n",
    "# # Set the number of trials to run\n",
    "# rescale0 = 1\n",
    "# tol           = 5e-3\n",
    "# sat_tol = 1e-5\n",
    "# max_iters     = int(1e3)\n",
    "# delta         = 1e-3\n",
    "\n",
    "\n",
    "# dim = 2; \n",
    "# int_samples = int(100)\n",
    "# int_samples_line = int(100)\n",
    "# x0      = -15*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.ones(dim, dtype=torch.double)\n",
    "\n",
    "# t     = 1e4 # int(2e2)/delta\n",
    "\n",
    "\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# avg_trials = 1\n",
    "# def f(x):\n",
    "#   return Levy(x)\n",
    "# def f_numpy(x):\n",
    "#   return Levy_numpy(x)\n",
    "\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Levy'\n",
    "\n",
    "# # Set the number of trials to run\n",
    "# dim = 20; \n",
    "# x0      = -15*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.ones(dim, dtype=torch.double)\n",
    "# tol           = 5e-3\n",
    "# sat_tol = 1e-5\n",
    "# max_iters     = int(1e3)\n",
    "\n",
    "# # Important parameters\n",
    "# delta         = 1e-2 # Smaller delta => more samples required but fewer iterations\n",
    "# t     = int(2e2)/delta\n",
    "\n",
    "# int_samples = int(100)\n",
    "# int_samples_line = int(100)\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "avg_trials = 1\n",
    "def f(x):\n",
    "  return Levy(x)\n",
    "def f_numpy(x):\n",
    "  return Levy_numpy(x)\n",
    "\n",
    "ax_bry  = 20\n",
    "f_name  = 'Levy'\n",
    "\n",
    "# Set the number of trials to run\n",
    "dim = 500; \n",
    "x0      = -15*torch.ones(dim, dtype=torch.double)\n",
    "x_true  = torch.ones(dim, dtype=torch.double)\n",
    "tol           = 5e-3\n",
    "sat_tol = 1e-5\n",
    "max_iters     = int(1e3)\n",
    "\n",
    "# Important parameters\n",
    "delta         = 1e-2 # Smaller delta => more samples required but fewer iterations\n",
    "t     = 100#int(2e2)/delta\n",
    "\n",
    "int_samples = int(100)\n",
    "int_samples_line = int(1000)\n",
    "\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Rastrigin(x)\n",
    "# def f_numpy(x):\n",
    "#   return Rastrigin_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Rastrigin'\n",
    "\n",
    "# dim = 2; int_samples = int(1000);\n",
    "# int_samples_line = int(100)\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "# t = int(2e1)/delta\n",
    "\n",
    "\n",
    "\n",
    "# # # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Ackley(x)\n",
    "# def f_numpy(x):\n",
    "#   return Ackley_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Ackley'\n",
    "\n",
    "# dim = 2; int_samples = int(1000);\n",
    "# int_samples_line = int(100)\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "# t = int(2e1)/delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Search Version - No Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hj_md_ls = HJ_MD_LS(f,f_numpy,f_name, x_true, delta=delta,\n",
    "                    int_samples=int_samples,int_samples_line=int_samples_line, t=t, max_iters=max_iters, tol=tol, \n",
    "                    verbose=True,saturate_tol=sat_tol, line_integration_method=\"GH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize accumulators for averages\n",
    "avg_func_evals = 0\n",
    "sum_elapsed_time = 0\n",
    "total_iterations = 0  # To store total iterations across trials\n",
    "avg_completion_error = 0  # To store completion error across trials\n",
    "avg_rescale_factor_reached = 0  # To store rescale factor reached across trials\n",
    "convergened_count = 0\n",
    "avg_successful_ls = 0\n",
    "# Run the specified number of trials\n",
    "for _ in range(avg_trials):\n",
    "    start_time = time.time()  # Record the start time\n",
    "    hj_md_ls.t = t\n",
    "\n",
    "\n",
    "    # Execute the HJ_MAD_CD algorithm and retrieve results\n",
    "    x_opt_ls, xk_hist_ls, xk_error_hist_ls, fk_hist_ls, successful_ls_portion = hj_md_ls.run(x0)\n",
    "\n",
    "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "    sum_elapsed_time += elapsed_time  # Accumulate elapsed time\n",
    "\n",
    "    total_iterations += len(xk_error_hist_ls)  # Add iterations used in this trial\n",
    "    avg_func_evals += len(xk_error_hist_ls) * int_samples  # Update average function evaluations\n",
    "    avg_completion_error += torch.norm(x_opt_ls -x_true) # Ensure the final error is the true error \n",
    "    avg_successful_ls += successful_ls_portion\n",
    "    avg_rescale_factor_reached += hj_md_ls.rescale0\n",
    "\n",
    "    if xk_error_hist_ls[-1] <= tol:\n",
    "        convergened_count += 1\n",
    "\n",
    "\n",
    "    #print(f\"Elapsed time: {elapsed_time:.4f} seconds\")  # Print elapsed time for the current trial\n",
    "\n",
    "# Compute averages after all trials\n",
    "avg_func_evals /= avg_trials  # Average function evaluations per trial\n",
    "average_iterations = total_iterations / avg_trials  # Average number of iterations per trial\n",
    "avg_completion_error /= avg_trials  # Average completion error across all trials\n",
    "avg_rescale_factor_reached /= avg_trials  # Average rescale factor reached across all trials\n",
    "portion_converged = convergened_count / avg_trials\n",
    "avg_successful_ls /= avg_trials\n",
    "# Output results\n",
    "print(f\"\\n\\nSummary of Results for {avg_trials} Trials HJ-MD-LS:\")\n",
    "print(\"=\" * 40)\n",
    "#print(f\"{'Average Function Evaluations:':<35} {avg_func_evals}\")\n",
    "print(f\"{'Average Completion Error:':<35} {avg_completion_error:.2e} (Tolerance: {tol:.2e})\")\n",
    "print(f\"{'Portion Converged:':<35} {portion_converged:.2%}\")\n",
    "print(f\"{'Average Successful Linesearch:':<35} {avg_successful_ls:.2%}\")\n",
    "print(f\"{'Average Iterations to Convergence/Stopping:':<35} {average_iterations:.2f}\")\n",
    "print(f\"{'Average Rescale Factor Reached:':<35} {avg_rescale_factor_reached:.2e}\")\n",
    "print(f\"{'Average Elapsed Time:':<35} {sum_elapsed_time / avg_trials:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-AcVUFHfahc"
   },
   "source": [
    "## Run HJ-MAD, Fixed time, stepsize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # No Line Search\n",
    "# int_samples_line = int(0.0)\n",
    "# hj_md = HJ_MD_LS(f,f_numpy,f_name, x_true, delta=delta,\n",
    "#                     int_samples=int_samples,int_samples_line=int_samples_line, t=t, max_iters=max_iters, tol=tol, \n",
    "#                     verbose=True,rescale0=rescale0,saturate_tol=sat_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_trials=2\n",
    "# # Initialize accumulators for averages\n",
    "# avg_func_evals = 0\n",
    "# sum_elapsed_time = 0\n",
    "# total_iterations = 0  # To store total iterations across trials\n",
    "# avg_completion_error = 0  # To store completion error across trials\n",
    "# avg_rescale_factor_reached = 0  # To store rescale factor reached across trials\n",
    "# convergened_count = 0\n",
    "# avg_successful_ls = 0\n",
    "# # Run the specified number of trials\n",
    "# for _ in range(avg_trials):\n",
    "#     start_time = time.time()  # Record the start time\n",
    "#     hj_md.rescale0 = rescale0\n",
    "\n",
    "#     # Execute the HJ_MAD_CD algorithm and retrieve results\n",
    "#     x_opt, xk_hist, xk_error_hist, fk_hist, successful_ls_portion = hj_md.run(x0)\n",
    "\n",
    "#     elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "#     sum_elapsed_time += elapsed_time  # Accumulate elapsed time\n",
    "\n",
    "#     total_iterations += len(xk_error_hist)  # Add iterations used in this trial\n",
    "#     avg_func_evals += len(xk_error_hist) * int_samples  # Update average function evaluations\n",
    "#     avg_completion_error += torch.norm(x_opt-x_true)  # Ensure the final error is the true error \n",
    "#     avg_successful_ls += successful_ls_portion\n",
    "#     avg_rescale_factor_reached += hj_md.rescale0\n",
    "\n",
    "#     if xk_error_hist[-1] <= tol:\n",
    "#         convergened_count += 1\n",
    "\n",
    "\n",
    "#     #print(f\"Elapsed time: {elapsed_time:.4f} seconds\")  # Print elapsed time for the current trial\n",
    "\n",
    "# # Compute averages after all trials\n",
    "# avg_func_evals /= avg_trials  # Average function evaluations per trial\n",
    "# average_iterations = total_iterations / avg_trials  # Average number of iterations per trial\n",
    "# avg_completion_error /= avg_trials  # Average completion error across all trials\n",
    "# avg_rescale_factor_reached /= avg_trials  # Average rescale factor reached across all trials\n",
    "# portion_converged = convergened_count / avg_trials\n",
    "# avg_successful_ls /= avg_trials\n",
    "# # Output results\n",
    "# print(f\"\\n\\nSummary of Results for {avg_trials} Trials HJ-MAD, Fixed time, stepsize = 1:\")\n",
    "# print(\"=\" * 40)\n",
    "# #print(f\"{'Average Function Evaluations:':<35} {avg_func_evals}\")\n",
    "# print(f\"{'Average Completion Error:':<35} {avg_completion_error:.2e} (Tolerance: {tol:.2e})\")\n",
    "# print(f\"{'Portion Converged:':<35} {portion_converged:.2%}\")\n",
    "# if int_samples_line > 0:\n",
    "#     print(f\"{'Average Successful Linesearch:':<35} {avg_successful_ls:.2%}\")\n",
    "# print(f\"{'Average Iterations to Convergence/Stopping:':<35} {average_iterations:.2f}\")\n",
    "# print(f\"{'Average Rescale Factor Reached:':<35} {avg_rescale_factor_reached:.2e}\")\n",
    "# print(f\"{'Average Elapsed Time:':<35} {sum_elapsed_time / avg_trials:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBT0oupCFD_u"
   },
   "source": [
    "### Generate Convergence Histories and Optimization Path Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "gHiwldOKLkKT",
    "outputId": "e50a8767-a37d-4e8a-965d-9cf9349bf15e"
   },
   "outputs": [],
   "source": [
    "\n",
    "title_fontsize = 22\n",
    "fontsize       = 18\n",
    "fig1 = plt.figure()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = plt.axes()\n",
    "\n",
    "# ax.semilogy(xk_error_hist_MAD, color='red', linewidth=3)\n",
    "# ax.semilogy(xk_error_hist, color='blue', linewidth=3);\n",
    "#ax.semilogy(xk_error_hist_no_mo, color='green', linestyle='--', linewidth=3);\n",
    "ax.semilogy(xk_error_hist_ls, color='red', linewidth=3);\n",
    "# ax.semilogy(xk_error_hist_ls_no_mo, color='red', linestyle='--', linewidth=3);\n",
    "\n",
    "ax.set_title(f'Dims={dim},Func={f_name},\\n Adaptive Rescale Factor', fontsize=title_fontsize)\n",
    "ax.set_xlabel(\"Iterations\", fontsize=title_fontsize)\n",
    "ax.set_ylabel(\"Errors\", fontsize=title_fontsize)\n",
    "ax.legend(['HJ-MD','HJ-MD-LS'],fontsize=fontsize)\n",
    "# title_str = 'Relative Errors'\n",
    "# ax.set_title(title_str, fontsize=title_fontsize)\n",
    "ax.tick_params(labelsize=fontsize, which='both', direction='in')\n",
    "\n",
    "# save_str = 'griewank_error_hist.png'\n",
    "# fig1.savefig(save_str, dpi=300 , bbox_inches=\"tight\", pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "3cYDR5eYFNFm",
    "outputId": "2d3f6069-c74a-4ae7-f9a4-77c1bc19578e"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = plt.axes()\n",
    "#ax.semilogy(fk_hist, color='blue', linewidth=3);\n",
    "#ax.semilogy(fk_hist_no_mo, color='green', linestyle='--', linewidth=3);\n",
    "ax.semilogy(fk_hist_ls, color='red', linewidth=3);\n",
    "#ax.semilogy(fk_hist_ls_no_mo, color='red', linestyle='--', linewidth=3);\n",
    "\n",
    "ax.set_xlabel(\"Iterations\", fontsize=title_fontsize)\n",
    "ax.set_ylabel(\"fk\", fontsize=title_fontsize)\n",
    "ax.legend(['HJ-MD','HJ-MD-LS'],fontsize=fontsize)\n",
    "title_str = 'Objective Function Values'\n",
    "ax.set_title(title_str, fontsize=title_fontsize)\n",
    "ax.tick_params(labelsize=fontsize, which='both', direction='in')\n",
    "\n",
    "# save_str = 'griewank_func_hist.png'\n",
    "# fig1.savefig(save_str, dpi=300 , bbox_inches=\"tight\", pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnWYfPeIR15H"
   },
   "source": [
    "## 2D Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "OGEzn9rLTAbV",
    "outputId": "6293e921-9c2b-42fb-cf53-d3f728623162"
   },
   "outputs": [],
   "source": [
    "# if dim == 2:\n",
    "\n",
    "if f_name == 'Levy':\n",
    "  x0      = -15*torch.ones(dim, dtype=torch.double)\n",
    "  x_true  = torch.ones(dim, dtype=torch.double)\n",
    "else:\n",
    "  x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "  x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "surface_plot_resolution = 50\n",
    "ax_bry = 15\n",
    "x = np.linspace(-ax_bry, ax_bry, surface_plot_resolution)\n",
    "y = np.linspace(-ax_bry, ax_bry, surface_plot_resolution)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "n_features = 2\n",
    "\n",
    "t_final = t\n",
    "\n",
    "Z                 = np.zeros(X.shape)\n",
    "Z_MAD             = np.zeros(X.shape)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "  for j in range(X.shape[1]):\n",
    "    Z[i,j] = f(torch.FloatTensor([X[i,j],Y[i,j]]).view(1,n_features))  \n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.contourf(X, Y, Z, 20, cmap=plt.get_cmap('gray'))\n",
    "plt.style.use('default')\n",
    "\n",
    "title_fontsize = 22\n",
    "fontsize       = 15\n",
    "#coordinate_wise_xk_hist_np = np.vstack(xk_hist)\n",
    "\n",
    "\n",
    "#ax.plot(np.vstack(xk_hist)[:,0], np.vstack(xk_hist)[:,1], 'g-o')\n",
    "\n",
    "#ax.plot(np.vstack(xk_hist_no_mo)[:,0], np.vstack(xk_hist_no_mo)[:,1], '-o', color='purple')\n",
    "\n",
    "ax.plot(np.vstack(xk_hist_ls)[:,0], np.vstack(xk_hist_ls)[:,1], 'b-o')\n",
    "\n",
    "\n",
    "ax.plot(x_true[0], x_true[1], 'rx', markeredgewidth=3, markersize=12)\n",
    "ax.plot(x0[0], x0[1], 'x', markeredgewidth=3, markersize=12, color='cyan')\n",
    "\n",
    "ax.legend(['HJ-MD', 'HJ-MD-LS', 'global min', 'initial guess'], fontsize=12, facecolor='white', markerfirst=False)\n",
    "\n",
    "ax.set_xlim(-ax_bry,ax_bry)\n",
    "cb = plt.colorbar(im)\n",
    "\n",
    "# save_loc = 'optimization_paths.png'\n",
    "# plt.savefig(save_loc,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive 2D Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    ax_bry_3D_plot = 20\n",
    "    surface_plot_resolution = 50\n",
    "    x = np.linspace(-ax_bry_3D_plot, ax_bry_3D_plot, surface_plot_resolution)\n",
    "    y = np.linspace(-ax_bry_3D_plot, ax_bry_3D_plot, surface_plot_resolution)\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    # Convert PyTorch tensors to NumPy\n",
    "    # xk_hist_MAD_np = xk_hist_MAD.numpy()\n",
    "    coordinate_wise_xk_hist_np = np.vstack(xk_hist_cd)\n",
    "\n",
    "    # # Ensure z_values are scalars\n",
    "    # HJ_MAD_f_values = np.array([\n",
    "    #     f(torch.FloatTensor([[xk_hist_MAD_np[i, 0], xk_hist_MAD_np[i, 1]]])).item()\n",
    "    #     for i in range(len(xk_hist_MAD_np))\n",
    "    # ])\n",
    "\n",
    "    HJ_MAD_CD_f_values = np.array([\n",
    "        f(torch.FloatTensor([[coordinate_wise_xk_hist_np[i, 0], coordinate_wise_xk_hist_np[i, 1]]])).item()\n",
    "        for i in range(len(coordinate_wise_xk_hist_np))\n",
    "    ])\n",
    "\n",
    "    # Global minimum and initial guess\n",
    "    if x_true.dim() == 1:\n",
    "        x_true = x_true.unsqueeze(0)\n",
    "    global_min_f = f(x_true).item()\n",
    "\n",
    "    # Initial guess point\n",
    "    if x0.dim() == 1:\n",
    "        x0 = x0.unsqueeze(0)\n",
    "    f_initial = f(x0).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # Create surface trace\n",
    "    surface_trace = go.Surface(\n",
    "        z=Z, x=X, y=Y, colorscale='Viridis', showscale=True, name='Surface'\n",
    "    )\n",
    "\n",
    "    # # Create optimization paths\n",
    "    # HJ_MAD_trace = go.Scatter3d(\n",
    "    #     x=xk_hist_MAD_np[:, 0],\n",
    "    #     y=xk_hist_MAD_np[:, 1],\n",
    "    #     z=HJ_MAD_f_values,\n",
    "    #     mode='lines+markers',\n",
    "    #     marker=dict(size=5, color='red'),\n",
    "    #     line=dict(color='red', width=3),\n",
    "    #     name='HJ-MAD'\n",
    "    # )\n",
    "\n",
    "    HJ_MAD_CD_trace = go.Scatter3d(\n",
    "        x=coordinate_wise_xk_hist_np[:, 0],\n",
    "        y=coordinate_wise_xk_hist_np[:, 1],\n",
    "        z=HJ_MAD_CD_f_values,\n",
    "        mode='lines+markers',\n",
    "        marker=dict(size=5, color='blue'),\n",
    "        line=dict(color='blue', width=3),\n",
    "        name='HJ-MAD-CD'\n",
    "    )\n",
    "\n",
    "    # Global minimum point\n",
    "    global_min_trace = go.Scatter3d(\n",
    "        x=[x_true[0, 0].item()],\n",
    "        y=[x_true[0, 1].item()],\n",
    "        z=[global_min_f],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='black', symbol='x'),\n",
    "        name='Global min'\n",
    "    )\n",
    "\n",
    "    # Initial guess point\n",
    "    initial_guess_trace = go.Scatter3d(\n",
    "        x=[x0[0, 0].item()],\n",
    "        y=[x0[0, 1].item()],\n",
    "        z=[f_initial],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='green', symbol='x'),\n",
    "        name='Initial guess'\n",
    "    )\n",
    "\n",
    "    # Combine traces\n",
    "    fig = go.Figure(data=[surface_trace, HJ_MAD_CD_trace, global_min_trace, initial_guess_trace])\n",
    "\n",
    "    # Set layout details\n",
    "    fig.update_layout(\n",
    "        title=\"Interactive 3D Optimization Path\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X-axis\",\n",
    "            yaxis_title=\"Y-axis\",\n",
    "            zaxis_title=\"f-axis\",\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "        legend=dict(\n",
    "            x=0.02,  # Adjust the x position of the legend\n",
    "            y=0.98,  # Adjust the y position of the legend\n",
    "            bgcolor='rgba(255, 255, 255, 0.5)',  # Set background color with transparency\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show interactive plot\n",
    "    fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "\n",
    "    # Create the 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot the surface\n",
    "    ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none', zorder=1)\n",
    "\n",
    "    # # Plot the HJ-MAD optimization path\n",
    "    # ax.plot(xk_hist_MAD_np[:, 0], xk_hist_MAD_np[:, 1], HJ_MAD_f_values, '-o', color='red', label=\"HJ-MAD\", zorder=2)\n",
    "\n",
    "    # Plot the HJ-MAD-CD optimization path\n",
    "    ax.plot(coordinate_wise_xk_hist_np[:, 0], coordinate_wise_xk_hist_np[:, 1], HJ_MAD_CD_f_values, '-o', color='blue', label=\"HJ-MAD-CD\", zorder=2)\n",
    "\n",
    "    ax.plot(\n",
    "        [x_true[0, 0].item()],  # Wrap in list\n",
    "        [x_true[0, 1].item()],  # Wrap in list\n",
    "        [global_min_f],  # Wrap in list\n",
    "        'x', color='black', label=\"Global min\", zorder=3\n",
    "    )\n",
    "    ax.plot(\n",
    "        [x0[0, 0].item()],  # Wrap in list\n",
    "        [x0[0, 1].item()],  # Wrap in list\n",
    "        [f_initial],  # Wrap in list\n",
    "        'x', color='green', label=\"Initial guess\", zorder=3\n",
    "    )\n",
    "\n",
    "    # Set view angle\n",
    "    ax.view_init(elev=50, azim=30)  # Increase the elevation angle to 90 degrees\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    ax.set_zlabel('f-axis')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
