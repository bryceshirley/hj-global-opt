{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPOilvdqgxGu"
   },
   "source": [
    "# This notebook is based on the paper: \"Global-Convergence-Nonconvex-Optimization\". \n",
    "\n",
    "The aim of this project is to find the global solution to  \n",
    "\\begin{equation}\n",
    "  \\min_{x \\in \\mathbb{R}^n} f(x).\n",
    "\\end{equation}\n",
    "\n",
    "To obtain a global minimizer, the main idea is to minimize the Moreau Envelop instead, which \"convexifies\" the original function. To make the Moreau envelope tractable, we use connections to Hamilton-Jacobi Equations via the Cole-Hopf and Hopf-Lax formulas to efficiently compute the gradients of the Moreau envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdiGOuXQA8qO",
    "outputId": "9d09c67a-aa8a-4138-9582-f52a98dc3a32"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from test_functions import Griewank, AlpineN1, Drop_Wave, Levy, Rastrigin, Ackley\n",
    "from test_functions import Griewank_numpy, AlpineN1_numpy, Drop_Wave_numpy, Levy_numpy, Rastrigin_numpy, Ackley_numpy\n",
    "\n",
    "from test_functions import MultiMinimaFunc, MultiMinimaAbsFunc\n",
    "from test_functions import MultiMinimaFunc_numpy, MultiMinimaAbsFunc_numpy\n",
    "\n",
    "seed   = 30\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "from hj_mad_cd import HJ_MAD, HJ_MAD_CoordinateDescent, HJ_MAD_CoordinateDescent_parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cb--RgyjfPAq"
   },
   "source": [
    "### Set up hyperparameters for HJ-MAD for different functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbHcFJ3e6Qfa"
   },
   "outputs": [],
   "source": [
    "# Default values\n",
    "delta         = 5e-3\n",
    "max_iters     = 1000 #int(1e5)\n",
    "tol           = 5e-2#7e-4\n",
    "momentum      = 0.64\n",
    "rescale0      = 0.5\n",
    "# Set the number of trials to run\n",
    "avg_trials = 1\n",
    "sat_tol = 1e-10\n",
    "\n",
    "# # def f(x):\n",
    "# #   return MultiMinimaFunc(x)\n",
    "# # def f_numpy(x):\n",
    "# #   return MultiMinimaFunc_numpy(x)\n",
    "# # ax_bry  = 30\n",
    "# # f_name  = 'MultiMinimaFunc'\n",
    "# # dim = 1; int_samples = int(100);\n",
    "# # x0      = -30*torch.ones(dim, dtype=torch.double)\n",
    "# # x_true  = -1.51034569*torch.ones(dim, dtype=torch.double)\n",
    "\n",
    "# # delta         = 0.1\n",
    "# # max_iters     = int(100)\n",
    "# # tol           = 1e-3\n",
    "# # momentum = 0.5\n",
    "\n",
    "# # theta         = 1.0 # note: larger theta => easier to increase time\n",
    "# # beta          = 0.0\n",
    "# # t_min     = 1e-1\n",
    "# # t_max     = 300\n",
    "# # t_init    = 220\n",
    "# # alpha     = 0.1\n",
    "# # eta_min = 0.99\n",
    "# # eta_plus = 5.0\n",
    "# # eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Griewank(x)\n",
    "# def f_numpy(x):\n",
    "#   return Griewank_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Griewank'\n",
    "# dim = 2; int_samples = int(10000);\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "# rescale0      = 1\n",
    "# delta         = 1e-6\n",
    "# max_iters     = int(1e4)\n",
    "# tol           = 1e-4\n",
    "# momentum = 0.0\n",
    "\n",
    "# theta         = 1.0 # note: larger theta => easier to increase time\n",
    "# beta          = 0.9\n",
    "# t_min     = 1e-2/delta\n",
    "# t_max     = int(2)/delta\n",
    "# t_init    = 1e-2/delta\n",
    "# alpha     = 5e-2\n",
    "# eta_min = 0.99\n",
    "# eta_plus = 5.0\n",
    "# eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "def f(x):\n",
    "  return Griewank(x)\n",
    "def f_numpy(x):\n",
    "  return Griewank_numpy(x)\n",
    "ax_bry  = 20\n",
    "f_name  = 'Griewank'\n",
    "dim = 20; int_samples = int(1e6);#int(1000000);\n",
    "x0      = 15*torch.ones(dim, dtype=torch.double)\n",
    "x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "rescale0      = 2**(-15)\n",
    "delta         = 1e-6\n",
    "max_iters     = int(1e5)\n",
    "tol           = 5e-2\n",
    "momentum = 0.64\n",
    "\n",
    "theta         = 1.0 # note: larger theta => easier to increase time\n",
    "beta          = 0.9\n",
    "t_min     = 1e-1/delta\n",
    "t_max     = int(2e1)/delta\n",
    "t_init    = 1e-1/delta\n",
    "alpha     = 5e-2\n",
    "eta_min = 0.99\n",
    "eta_plus = 5.0\n",
    "eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "# # def f(x):\n",
    "# #   return Griewank(x)\n",
    "# # def f_numpy(x):\n",
    "# #   return Griewank_numpy(x)\n",
    "# # f_name  = 'Griewank'\n",
    "# # dim = 200; int_samples = int(100); # this one has higher dimension\n",
    "# # x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# # x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "# # rescale0      = 2**(-5)\n",
    "# # sat_tol = 1e-9 #7e-7 or 7e-10 (not sure) for 100 dims, 7e-8 for less than 100 dims\n",
    "# # theta     = 1.0 # note: larger theta => easier to increase time\n",
    "# # beta      = 0.9\n",
    "# # # momentum  = 0.5\n",
    "# # # beta      = 0.0\n",
    "# # momentum  = 0.0\n",
    "# # t_min     = 2e1\n",
    "# # t_max     = 1e5\n",
    "# # t_init    = 2e1\n",
    "# # alpha     = 1.2\n",
    "# # eta_min = 0.5\n",
    "# # eta_plus = 5.0\n",
    "# # eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Griewank(x)\n",
    "# def f_numpy(x):\n",
    "#   return Griewank_numpy(x)\n",
    "# f_name  = 'Griewank'\n",
    "# dim = 500; int_samples = int(100); \n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "# rescale0      = 2**(-6)#256\n",
    "# sat_tol = 1e-9 #7e-7 or 7e-10 (not sure) for 100 dims, 7e-8 for less than 100 dims\n",
    "# theta     = 1.0 # note: larger theta => easier to increase time\n",
    "# beta      = 0.0\n",
    "# momentum  = 0.0\n",
    "# t_min     = 2e1\n",
    "# t_max     = 1e5\n",
    "# t_init    = 2e1\n",
    "# alpha     = 1.2\n",
    "# eta_min = 0.5\n",
    "# eta_plus = 5.0\n",
    "# eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Drop_Wave(x)\n",
    "# def f_numpy(x):\n",
    "#   return Drop_Wave_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# max_iters     = 1000\n",
    "# f_name  = 'Drop_Wave'\n",
    "# rescale0      = 1\n",
    "# dim = 2; int_samples = int(10000)\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "# momentum      = 0.5\n",
    "# delta         = 1e-4\n",
    "# theta         = 1.0 # note: larger theta => easier to increase time\n",
    "# beta          = 0.8\n",
    "# t_min     = 1e-6\n",
    "# t_max     = int(2e1)/delta\n",
    "# t_init    = 1e3\n",
    "# alpha     = 0.5\n",
    "# eta_min = 0.5\n",
    "# eta_plus = 5.0\n",
    "# eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return AlpineN1(x)\n",
    "# def f_numpy(x):\n",
    "#   return AlpineN1_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'AlpineN1'\n",
    "\n",
    "# dim = 2; int_samples = int(100000)# int(10000);\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "# momentum      = 0.45\n",
    "\n",
    "# theta         = 1.0 # note: larger theta => easier to increase time\n",
    "# beta          = 0.0\n",
    "# # t_max     = int(2e1)/delta\n",
    "# # t_init    = 1e-3\n",
    "# # t_min     = t_init\n",
    "# t_max     = int(2e3)/delta\n",
    "# t_init    = 1e-3\n",
    "# t_min     = 1e-4\n",
    "# alpha     = 0.25\n",
    "# eta_min = 0.6\n",
    "# eta_plus = 5.0\n",
    "# eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Levy(x)\n",
    "# def f_numpy(x):\n",
    "#   return Levy_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Levy'\n",
    "\n",
    "# # Set the number of trials to run\n",
    "# rescale0 = 2**(-7)\n",
    "# tol           = 5e-2\n",
    "# sat_tol = 1e-12\n",
    "# max_iters     = 1000\n",
    "\n",
    "# dim = 2; int_samples = int(500000)\n",
    "# x0      = -15*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.ones(dim, dtype=torch.double)\n",
    "\n",
    "# theta         = 0.9 # note: larger theta => easier to increase time\n",
    "# beta          = 0.5\n",
    "\n",
    "# t_max     = int(2e5)/delta\n",
    "# t_init    = 1e6\n",
    "# t_min     = 1e2\n",
    "# alpha     = 0.25\n",
    "# eta_min = 0.6\n",
    "# eta_plus = 1.5\n",
    "# eta_vec = [eta_min, eta_plus]\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Rastrigin(x)\n",
    "# def f_numpy(x):\n",
    "#   return Rastrigin_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Rastrigin'\n",
    "# delta=5e-3\n",
    "# dim = 2; int_samples = int(10000);\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "# momentum      = 0.25\n",
    "# theta         = 1.0 # note: larger theta => easier to increase time\n",
    "# beta          = 0.5\n",
    "# t_max     = int(2e1)/delta\n",
    "# t_init    = 5.0\n",
    "# t_min     = t_init\n",
    "# alpha     = 0.5\n",
    "# eta_min = 0.5\n",
    "# eta_plus = 5.0\n",
    "# eta_vec = [eta_min, eta_plus]\n",
    "# tol=2e-10\n",
    "\n",
    "# # # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# def f(x):\n",
    "#   return Ackley(x)\n",
    "# def f_numpy(x):\n",
    "#   return Ackley_numpy(x)\n",
    "# ax_bry  = 20\n",
    "# f_name  = 'Ackley'\n",
    "\n",
    "# dim = 2; int_samples = int(100000);\n",
    "# x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "# x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "# momentum      = 0.25\n",
    "# theta         = 1.0 # note: larger theta => easier to increase time\n",
    "# beta          = 0.9\n",
    "# t_max     = int(2e1)/delta\n",
    "# t_init    = 1e-3\n",
    "# t_min     = t_init\n",
    "# alpha     = 5e-1\n",
    "# eta_min = 0.5\n",
    "# eta_plus = 5.0\n",
    "# eta_vec = [eta_min, eta_plus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-AcVUFHfahc"
   },
   "source": [
    "Run HJ-MAD and average its results over avg_trials trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Under this transformation the standard deviation of the Gaussian is 1, hence we have more control over t and delta\n",
    "\n",
    "# Create an instance of HJ_MAD_CoordinateDescent\n",
    "if f_name == 'Ackley':\n",
    "    hj_mad_cd_GHQ = HJ_MAD_CoordinateDescent(f, x_true, delta=delta*1e-10,\n",
    "                    int_samples=int(1000), t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=sat_tol,integration_method='GHQ')\n",
    "elif f_name == 'Griewank' and dim == 500:\n",
    "    tol           = 5e-2\n",
    "    hj_mad_cd_GHQ = HJ_MAD_CoordinateDescent(f, x_true, delta= 1e-8,\n",
    "                    int_samples=int(150), t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=1e-10,integration_method='GHQ')\n",
    "\n",
    "    hj_mad_cd_MC = HJ_MAD_CoordinateDescent(f, x_true, delta=1e-2,\n",
    "                    int_samples=int(500), t_vec=[t_init, t_min*1e-2, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=momentum,saturate_tol=sat_tol,integration_method=\"MC\")\n",
    "\n",
    "    # hj_mad_cd_NMC = HJ_MAD_CoordinateDescent(f, x_true, delta=1e-6,\n",
    "    #                 int_samples=int(1000), t_vec=[t_init*1e4, t_min, t_max*1e5], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "    #                 beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "    #                 momentum=momentum,saturate_tol=sat_tol,integration_method=\"MC\")\n",
    "    \n",
    "\n",
    "elif f_name == 'Rastrigin':\n",
    "    tol = 1e-4\n",
    "    hj_mad_cd_GHQ = HJ_MAD_CoordinateDescent(f, x_true, delta=delta,\n",
    "                    int_samples=int(10000), t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=sat_tol,integration_method='GHQ')\n",
    "\n",
    "    hj_mad_cd_MC = HJ_MAD_CoordinateDescent(f, x_true, delta=delta,\n",
    "                    int_samples=int(5000), t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=sat_tol*1e5,integration_method=\"MC\")\n",
    "\n",
    "    hj_mad_cd_NMC = HJ_MAD_CoordinateDescent(f, x_true, delta=5e-5,\n",
    "                    int_samples=int(5000), t_vec=[20, 1e-5, 1e5], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.1,saturate_tol=sat_tol*1e5,integration_method=\"NMC\")\n",
    "elif f_name == 'Levy': # All have been tuned\n",
    "    hj_mad_cd_GHQ = HJ_MAD_CoordinateDescent(f, x_true, delta=1e-13,\n",
    "                    int_samples=int(80), t_vec=[0.5, 0.5, 1], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.6,saturate_tol=sat_tol,integration_method='GHQ')\n",
    "    \n",
    "    hj_mad_cd_MC = HJ_MAD_CoordinateDescent(f, x_true, delta=delta,\n",
    "                    int_samples=int(100000), t_vec=[t_init, t_min, t_max], max_iters=10, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=momentum,saturate_tol=sat_tol,integration_method=\"MC\")\n",
    "\n",
    "    hj_mad_cd_NMC = HJ_MAD_CoordinateDescent(f, x_true, delta=1e-2,\n",
    "                        int_samples=int(10), t_vec=[10, 1e-2, 1000], max_iters=10, tol=tol, alpha=alpha,\n",
    "                        beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                        momentum=0.5,saturate_tol=sat_tol,integration_method=\"NMC\")\n",
    "elif f_name == 'AlpineN1': # None are tuned\n",
    "    hj_mad_cd_GHQ = HJ_MAD_CoordinateDescent(f, x_true, delta=5e-15,\n",
    "                    int_samples=int(1000), t_vec=[50, 10, 60], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=sat_tol,integration_method='GHQ')\n",
    "    \n",
    "    hj_mad_cd_MC = HJ_MAD_CoordinateDescent(f, x_true, delta=delta,\n",
    "                    int_samples=int_samples, t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=sat_tol,integration_method=\"MC\")\n",
    "\n",
    "    hj_mad_cd_NMC = HJ_MAD_CoordinateDescent(f, x_true, delta=delta,\n",
    "                    int_samples=int(50), t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=sat_tol,integration_method=\"NMC\")\n",
    "    \n",
    "elif f_name == 'Drop_Wave':\n",
    "    tol = 5e-2\n",
    "    hj_mad_cd_GHQ = HJ_MAD_CoordinateDescent(f, x_true, delta=1e-21,\n",
    "                    int_samples=int(1000), t_vec=[1e6, 1e4, 1e6], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.4,saturate_tol=sat_tol,integration_method='GHQ')\n",
    "else:\n",
    "    hj_mad_cd_GHQ = HJ_MAD_CoordinateDescent(f, x_true, delta=delta,\n",
    "                    int_samples=int_samples, t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=False, verbose=True,rescale0=rescale0,\n",
    "                    momentum=0.0,saturate_tol=sat_tol,integration_method='GHQ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize accumulators for averages\n",
    "# avg_func_evals = 0\n",
    "# sum_elapsed_time = 0\n",
    "# total_iterations = 0  # To store total iterations across trials\n",
    "\n",
    "# # Run the specified number of trials\n",
    "# for _ in range(avg_trials):\n",
    "#     start_time = time.time()  # Record the start time\n",
    "\n",
    "#     # Execute the HJ_MAD_CD algorithm and retrieve results\n",
    "#     x_opt_cd_GHQ, coordinate_wise_xk_hist_GHQ, xk_hist_cd_GHQ, xk_error_hist_cd_GHQ, fk_hist_cd_GHQ = hj_mad_cd_GHQ.run(x0, num_cycles=20)\n",
    "\n",
    "#     elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "#     sum_elapsed_time += elapsed_time  # Accumulate elapsed time\n",
    "\n",
    "#     total_iterations += len(xk_error_hist_cd_GHQ)  # Add iterations used in this trial\n",
    "#     avg_func_evals += len(xk_error_hist_cd_GHQ) * int_samples  # Update average function evaluations\n",
    "\n",
    "#     print(f\"Elapsed time: {elapsed_time:.4f} seconds\")  # Print elapsed time for the current trial\n",
    "\n",
    "\n",
    "# # Compute averages after all trials\n",
    "# avg_func_evals /= avg_trials  # Average function evaluations per trial\n",
    "# average_iterations = total_iterations / avg_trials  # Average number of iterations per trial\n",
    "\n",
    "# # Output results\n",
    "# # print('\\n\\n avg_func_evals = ', avg_func_evals)\n",
    "# print(f\"Average iterations before convergence/stopping: {average_iterations:.2f}\")\n",
    "# print(f\"Average elapsed time: {sum_elapsed_time / avg_trials:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Initialize accumulators for averages\n",
    "# avg_func_evals = 0\n",
    "# sum_elapsed_time = 0\n",
    "# total_iterations = 0  # To store total iterations across trials\n",
    "\n",
    "# hj_mad_cd_MC.saturate_tol = 1e-4\n",
    "# hj_mad_cd_MC.delta = 1e-3\n",
    "\n",
    "# # #hj_mad_cd_MC.theta     = 0.99 # note: larger theta => easier to increase time\n",
    "# # beta      = 0.0\n",
    "# # momentum  = 0.0\n",
    "# # t_min     = 2e1\n",
    "# # t_max     = 1e5\n",
    "# # t_init    = 2e1\n",
    "# # alpha     = 1.2\n",
    "# # eta_min = 0.5\n",
    "# # eta_plus = 5.0\n",
    "\n",
    "# # Run the specified number of trials\n",
    "# for _ in range(avg_trials):\n",
    "#     start_time = time.time()  # Record the start time\n",
    "\n",
    "#     # Execute the HJ_MAD_CD algorithm and retrieve results\n",
    "#     x_opt_cd_MC, coordinate_wise_xk_hist_MC, xk_hist_cd_MC, xk_error_hist_cd_MC, fk_hist_cd_MC = hj_mad_cd_MC.run(x0, num_cycles=2)\n",
    "\n",
    "#     elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "#     sum_elapsed_time += elapsed_time  # Accumulate elapsed time\n",
    "\n",
    "#     total_iterations += len(xk_error_hist_cd_MC)  # Add iterations used in this trial\n",
    "#     avg_func_evals += len(xk_error_hist_cd_MC) * int_samples  # Update average function evaluations\n",
    "\n",
    "#     print(f\"Elapsed time: {elapsed_time:.4f} seconds\")  # Print elapsed time for the current trial\n",
    "\n",
    "\n",
    "# # Compute averages after all trials\n",
    "# avg_func_evals /= avg_trials  # Average function evaluations per trial\n",
    "# average_iterations = total_iterations / avg_trials  # Average number of iterations per trial\n",
    "\n",
    "# # Output results\n",
    "# # print('\\n\\n avg_func_evals = ', avg_func_evals)\n",
    "# print(f\"Average iterations before convergence/stopping: {average_iterations:.2f}\")\n",
    "# print(f\"Average elapsed time: {sum_elapsed_time / avg_trials:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Initialize accumulators for averages\n",
    "# avg_func_evals = 0\n",
    "# sum_elapsed_time = 0\n",
    "# total_iterations = 0  # To store total iterations across trials\n",
    "\n",
    "# # Run the specified number of trials\n",
    "# for _ in range(avg_trials):\n",
    "#     start_time = time.time()  # Record the start time\n",
    "\n",
    "#     # Execute the HJ_MAD_CD algorithm and retrieve results\n",
    "#     x_opt_cd_NMC, coordinate_wise_xk_hist_NMC, xk_hist_cd_NMC, xk_error_hist_cd_NMC, fk_hist_cd_NMC = hj_mad_cd_NMC.run(x0, num_cycles=20)\n",
    "\n",
    "#     elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "#     sum_elapsed_time += elapsed_time  # Accumulate elapsed time\n",
    "\n",
    "#     total_iterations += len(xk_error_hist_cd_NMC)  # Add iterations used in this trial\n",
    "#     avg_func_evals += len(xk_error_hist_cd_NMC) * int_samples  # Update average function evaluations\n",
    "\n",
    "#     print(f\"Elapsed time: {elapsed_time:.4f} seconds\")  # Print elapsed time for the current trial\n",
    "\n",
    "\n",
    "# # Compute averages after all trials\n",
    "# avg_func_evals /= avg_trials  # Average function evaluations per trial\n",
    "# average_iterations = total_iterations / avg_trials  # Average number of iterations per trial\n",
    "\n",
    "# # Output results\n",
    "# # print('\\n\\n avg_func_evals = ', avg_func_evals)\n",
    "# print(f\"Average iterations before convergence/stopping: {average_iterations:.2f}\")\n",
    "# print(f\"Average elapsed time: {sum_elapsed_time / avg_trials:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an instance of HJ_MAD_CoordinateDescent\n",
    "# hj_mad_cd = HJ_MAD_CoordinateDescent_parallel(f, x_true, delta=delta,\n",
    "#                     int_samples=int_samples, t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "#                     beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False,plot=True, verbose=False,rescale0=rescale0,\n",
    "#                     momentum=momentum,saturate_tol=sat_tol,integration_method='MC')\n",
    "\n",
    "# # Initialize accumulators for averages\n",
    "# avg_func_evals = 0\n",
    "# sum_elapsed_time = 0\n",
    "# total_iterations = 0  # To store total iterations across trials\n",
    "\n",
    "# # Run the specified number of trials\n",
    "# for _ in range(avg_trials):\n",
    "#     start_time = time.time()  # Record the start time\n",
    "\n",
    "#     # Execute the HJ_MAD_CD algorithm and retrieve results\n",
    "#     x_opt_cd_para, coordinate_wise_xk_hist_para, xk_hist_cd_para, xk_error_hist_cd_para, fk_hist_cd_para = hj_mad_cd.run(x0, num_cycles=20)\n",
    "\n",
    "#     elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "#     sum_elapsed_time += elapsed_time  # Accumulate elapsed time\n",
    "\n",
    "#     total_iterations += len(xk_error_hist_cd_para)  # Add iterations used in this trial\n",
    "#     avg_func_evals += len(xk_error_hist_cd_para) * int_samples  # Update average function evaluations\n",
    "\n",
    "#     print(f\"Elapsed time: {elapsed_time:.4f} seconds\")  # Print elapsed time for the current trial\n",
    "\n",
    "\n",
    "# # Compute averages after all trials\n",
    "# avg_func_evals /= avg_trials  # Average function evaluations per trial\n",
    "# average_iterations = total_iterations / avg_trials  # Average number of iterations per trial\n",
    "\n",
    "# # Output results\n",
    "# print('\\n\\n avg_func_evals = ', avg_func_evals)\n",
    "# print(f\"Average iterations before convergence/stopping: {average_iterations:.2f}\")\n",
    "# print(f\"Average elapsed time: {sum_elapsed_time / avg_trials:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73eSi37bA9ak",
    "outputId": "8649873a-41e6-4860-b70e-762d57c05cdb"
   },
   "outputs": [],
   "source": [
    "int_samples = int(1e6);\n",
    "# rescale0=1\n",
    "# delta         = 5e-7\n",
    "# t_min     = 2e1\n",
    "# t_max     = 1e6\n",
    "# t_init    = 2e3#2e1\n",
    "# delta         = 5e-2\n",
    "# t_min     = 2e1\n",
    "# t_max     = 1e5\n",
    "# t_init    = 2e3#2e1\n",
    "# theta     = 0.7\n",
    "HJ_MAD_alg = HJ_MAD(f, x_true, delta=delta,\n",
    "                    int_samples=int_samples, t_vec=[t_init, t_min, t_max], max_iters=max_iters, tol=tol, alpha=alpha,\n",
    "                    beta=beta, eta_vec = eta_vec, theta=theta, fixed_time=False, verbose=True,rescale0=rescale0,momentum=0.5,\n",
    "                    integration_method='MC')\n",
    "# Initialize accumulators for averages\n",
    "avg_func_evals = 0\n",
    "sum_elapsed_time = 0\n",
    "total_iterations = 0  # To store total iterations across trials\n",
    "\n",
    "# Run the specified number of trials\n",
    "for _ in range(avg_trials):\n",
    "    #x0 = 10*torch.ones(dim, dtype=torch.double)\n",
    "    start_time = time.time()  # Record the start time\n",
    "\n",
    "    # Execute the HJ_MAD algorithm and retrieve results\n",
    "    x_opt_MAD, xk_hist_MAD, tk_hist_MAD, xk_error_hist_MAD, rel_grad_uk_norm_hist_MAD, fk_hist_MAD = HJ_MAD_alg.run(x0)\n",
    "\n",
    "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "    sum_elapsed_time += elapsed_time  # Accumulate elapsed time\n",
    "    \n",
    "    total_iterations += len(xk_error_hist_MAD)  # Add iterations used in this trial\n",
    "    avg_func_evals += len(xk_error_hist_MAD) * int_samples  # Update average function evaluations\n",
    "\n",
    "    print(f\"Elapsed time: {elapsed_time:.4f} seconds\")  # Print elapsed time for the current trial\n",
    "\n",
    "# Compute averages after all trials\n",
    "avg_func_evals /= avg_trials  # Average function evaluations per trial\n",
    "average_iterations = total_iterations / avg_trials  # Average number of iterations per trial\n",
    "\n",
    "# Output results\n",
    "print('\\n\\n avg_func_evals = ', avg_func_evals)\n",
    "print(f\"Average iterations before convergence: {average_iterations:.2f}\")\n",
    "print(f\"Average elapsed time: {sum_elapsed_time / avg_trials:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBT0oupCFD_u"
   },
   "source": [
    "### Generate Convergence Histories and Optimization Path Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "gHiwldOKLkKT",
    "outputId": "e50a8767-a37d-4e8a-965d-9cf9349bf15e"
   },
   "outputs": [],
   "source": [
    "\n",
    "title_fontsize = 22\n",
    "fontsize       = 18\n",
    "fig1 = plt.figure()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.semilogy(xk_error_hist_MAD, color='purple', linewidth=3,label='HJ-MAD(MC)');\n",
    "#ax.semilogy(xk_error_hist_cd_NMC, color='red', linewidth=3,label='HJ-MAD-NMC');\n",
    "ax.semilogy(xk_error_hist_cd_GHQ, color='blue', linewidth=3,label='HJ-MAD-CD-GHQ');\n",
    "ax.semilogy(xk_error_hist_cd_MC, color='green', linewidth=3,label='HJ-MAD-CD-MC');\n",
    "# ax.semilogy(xk_error_hist_EGD[0:len(xk_error_hist_GD)], 'm-', linewidth=3)\n",
    "#ax.semilogy(xk_error_hist_GD[0:len(xk_error_hist_GD)], 'g-', linewidth=3)\n",
    "ax.set_title(f'Dims={dim},Func={f_name},\\n Adaptive Rescale Factor', fontsize=title_fontsize)\n",
    "ax.set_xlabel(\"Iterations\", fontsize=title_fontsize)\n",
    "ax.set_ylabel(\"Errors\", fontsize=title_fontsize)\n",
    "ax.legend(fontsize=fontsize)\n",
    "# title_str = 'Relative Errors'\n",
    "# ax.set_title(title_str, fontsize=title_fontsize)\n",
    "ax.tick_params(labelsize=fontsize, which='both', direction='in')\n",
    "\n",
    "# save_str = 'griewank_error_hist.png'\n",
    "# fig1.savefig(save_str, dpi=300 , bbox_inches=\"tight\", pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "3cYDR5eYFNFm",
    "outputId": "2d3f6069-c74a-4ae7-f9a4-77c1bc19578e"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = plt.axes()\n",
    "ax.semilogy(fk_hist_MAD, color='red', linewidth=3,label='HJ-MAD');\n",
    "ax.semilogy(fk_hist_cd_NMC, color='red', linewidth=3,label='HJ-MAD-NMC');\n",
    "ax.semilogy(fk_hist_cd_GHQ, color='blue', linewidth=3,label='HJ-MAD-CD-GHQ');\n",
    "ax.semilogy(fk_hist_cd_MC, color='green', linewidth=3,label='HJ-MAD-CD-MC');\n",
    "\n",
    "ax.set_xlabel(\"Iterations\", fontsize=title_fontsize)\n",
    "ax.set_ylabel(\"fk\", fontsize=title_fontsize)\n",
    "ax.legend(fontsize=fontsize)\n",
    "title_str = 'Objective Function Values'\n",
    "ax.set_title(title_str, fontsize=title_fontsize)\n",
    "ax.tick_params(labelsize=fontsize, which='both', direction='in')\n",
    "\n",
    "# save_str = 'griewank_func_hist.png'\n",
    "# fig1.savefig(save_str, dpi=300 , bbox_inches=\"tight\", pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnWYfPeIR15H"
   },
   "source": [
    "## 2D Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "OGEzn9rLTAbV",
    "outputId": "6293e921-9c2b-42fb-cf53-d3f728623162"
   },
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "\n",
    "  if f_name == 'Levy':\n",
    "    x0      = -15*torch.ones(dim, dtype=torch.double)\n",
    "    x_true  = torch.ones(dim, dtype=torch.double)\n",
    "  else:\n",
    "    x0      = 10*torch.ones(dim, dtype=torch.double)\n",
    "    x_true  = torch.zeros(dim, dtype=torch.double)\n",
    "\n",
    "  surface_plot_resolution = 50\n",
    "  x = np.linspace(-ax_bry, ax_bry, surface_plot_resolution)\n",
    "  y = np.linspace(-ax_bry, ax_bry, surface_plot_resolution)\n",
    "\n",
    "  X, Y = np.meshgrid(x, y)\n",
    "  n_features = 2\n",
    "\n",
    "  t_final = t_max\n",
    "\n",
    "  Z                 = np.zeros(X.shape)\n",
    "  Z_MAD             = np.zeros(X.shape)\n",
    "\n",
    "  for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "      Z[i,j] = f(torch.FloatTensor([X[i,j],Y[i,j]]).view(1,n_features))  \n",
    "     \n",
    "\n",
    "  fig, ax = plt.subplots(1, 1)\n",
    "  im = ax.contourf(X, Y, Z, 20, cmap=plt.get_cmap('gray'))\n",
    "  plt.style.use('default')\n",
    "\n",
    "  title_fontsize = 22\n",
    "  fontsize       = 15\n",
    "\n",
    "  ax.plot(np.vstack(xk_hist_cd_MC)[:,0], np.vstack(xk_hist_cd_MC)[:,1], '-o', color='blue',label='HJ-MAD-CD-MC')\n",
    "  ax.plot(np.vstack(xk_hist_cd_GHQ)[:,0], np.vstack(xk_hist_cd_GHQ)[:,1], 'm-o', label='HJ-MAD-CD-GHQ')\n",
    "  ax.plot(np.vstack(xk_hist_cd_NMC)[:,0], np.vstack(xk_hist_cd_NMC)[:,1], 'm-o',label='HJ-MAD-CD-NMC')\n",
    "\n",
    "\n",
    "  ax.plot(x_true[0], x_true[1], 'rx', markeredgewidth=3, markersize=12,label='global min')\n",
    "  ax.plot(x0[0], x0[1], 'kx', markeredgewidth=3, markersize=12,label='initial guess')\n",
    "\n",
    "  ax.legend(fontsize=12, facecolor='white', markerfirst=False, loc='lower right')\n",
    "\n",
    "  ax.set_xlim(-ax_bry,ax_bry)\n",
    "  cb = plt.colorbar(im)\n",
    "\n",
    "  # save_loc = 'optimization_paths.png'\n",
    "  # plt.savefig(save_loc,bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive 2D Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    ax_bry_3D_plot = 20\n",
    "    surface_plot_resolution = 50\n",
    "    x = np.linspace(-ax_bry_3D_plot, ax_bry_3D_plot, surface_plot_resolution)\n",
    "    y = np.linspace(-ax_bry_3D_plot, ax_bry_3D_plot, surface_plot_resolution)\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    # Convert PyTorch tensors to NumPy\n",
    "    # xk_hist_MAD_np = xk_hist_MAD.numpy()\n",
    "    # coordinate_wise_xk_hist_np = np.vstack(xk_hist_cd)\n",
    "\n",
    "    # # Ensure z_values are scalars\n",
    "    # HJ_MAD_f_values = np.array([\n",
    "    #     f(torch.FloatTensor([[xk_hist_MAD_np[i, 0], xk_hist_MAD_np[i, 1]]])).item()\n",
    "    #     for i in range(len(xk_hist_MAD_np))\n",
    "    # ])\n",
    "\n",
    "    HJ_MAD_CD_f_values = np.array([\n",
    "        f(torch.FloatTensor([[np.vstack(xk_hist_cd_MC)[i, 0], np.vstack(xk_hist_cd_MC)[i, 1]]])).item()\n",
    "        for i in range(len(np.vstack(xk_hist_cd_MC)))\n",
    "    ])\n",
    "\n",
    "    # Global minimum and initial guess\n",
    "    if x_true.dim() == 1:\n",
    "        x_true = x_true.unsqueeze(0)\n",
    "    global_min_f = f(x_true).item()\n",
    "\n",
    "    # Initial guess point\n",
    "    if x0.dim() == 1:\n",
    "        x0 = x0.unsqueeze(0)\n",
    "    f_initial = f(x0).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # Create surface trace\n",
    "    surface_trace = go.Surface(\n",
    "        z=Z, x=X, y=Y, colorscale='Viridis', showscale=True, name='Surface'\n",
    "    )\n",
    "\n",
    "    # Create optimization paths\n",
    "    # HJ_MAD_trace = go.Scatter3d(\n",
    "    #     x=xk_hist_MAD_np[:, 0],\n",
    "    #     y=xk_hist_MAD_np[:, 1],\n",
    "    #     z=HJ_MAD_f_values,\n",
    "    #     mode='lines+markers',\n",
    "    #     marker=dict(size=5, color='red'),\n",
    "    #     line=dict(color='red', width=3),\n",
    "    #     name='HJ-MAD'\n",
    "    # )\n",
    "\n",
    "    HJ_MAD_CD_trace = go.Scatter3d(\n",
    "        x=np.vstack(xk_hist_cd_MC)[:, 0],\n",
    "        y=np.vstack(xk_hist_cd_MC)[:, 1],\n",
    "        z=HJ_MAD_CD_f_values,\n",
    "        mode='lines+markers',\n",
    "        marker=dict(size=5, color='blue'),\n",
    "        line=dict(color='blue', width=3),\n",
    "        name='HJ-MAD-CD'\n",
    "    )\n",
    "\n",
    "    # Global minimum point\n",
    "    global_min_trace = go.Scatter3d(\n",
    "        x=[x_true[0, 0].item()],\n",
    "        y=[x_true[0, 1].item()],\n",
    "        z=[global_min_f],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='black', symbol='x'),\n",
    "        name='Global min'\n",
    "    )\n",
    "\n",
    "    # Initial guess point\n",
    "    initial_guess_trace = go.Scatter3d(\n",
    "        x=[x0[0, 0].item()],\n",
    "        y=[x0[0, 1].item()],\n",
    "        z=[f_initial],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='green', symbol='x'),\n",
    "        name='Initial guess'\n",
    "    )\n",
    "\n",
    "    # Combine traces\n",
    "    fig = go.Figure(data=[surface_trace, HJ_MAD_CD_trace, global_min_trace, initial_guess_trace])\n",
    "\n",
    "    # Set layout details\n",
    "    fig.update_layout(\n",
    "        title=\"Interactive 3D Optimization Path\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X-axis\",\n",
    "            yaxis_title=\"Y-axis\",\n",
    "            zaxis_title=\"f-axis\",\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "        legend=dict(\n",
    "            x=0.02,  # Adjust the x position of the legend\n",
    "            y=0.98,  # Adjust the y position of the legend\n",
    "            bgcolor='rgba(255, 255, 255, 0.5)',  # Set background color with transparency\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show interactive plot\n",
    "    fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "\n",
    "    # Create the 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot the surface\n",
    "    ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none', zorder=1)\n",
    "\n",
    "    # Plot the HJ-MAD optimization path\n",
    "    # ax.plot(xk_hist_MAD_np[:, 0], xk_hist_MAD_np[:, 1], HJ_MAD_f_values, '-o', color='red', label=\"HJ-MAD\", zorder=2)\n",
    "\n",
    "    # Plot the HJ-MAD-CD optimization path\n",
    "    ax.plot(np.vstack(xk_hist_cd_MC)[:, 0], np.vstack(xk_hist_cd_MC)[:, 1], HJ_MAD_CD_f_values, '-o', color='blue', label=\"HJ-MAD-CD\", zorder=2)\n",
    "\n",
    "    ax.plot(\n",
    "        [x_true[0, 0].item()],  # Wrap in list\n",
    "        [x_true[0, 1].item()],  # Wrap in list\n",
    "        [global_min_f],  # Wrap in list\n",
    "        'x', color='black', label=\"Global min\", zorder=3\n",
    "    )\n",
    "    ax.plot(\n",
    "        [x0[0, 0].item()],  # Wrap in list\n",
    "        [x0[0, 1].item()],  # Wrap in list\n",
    "        [f_initial],  # Wrap in list\n",
    "        'x', color='green', label=\"Initial guess\", zorder=3\n",
    "    )\n",
    "\n",
    "    # Set view angle\n",
    "    ax.view_init(elev=50, azim=30)  # Increase the elevation angle to 90 degrees\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    ax.set_zlabel('f-axis')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
